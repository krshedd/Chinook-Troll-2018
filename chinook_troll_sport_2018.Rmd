---
title: "Chinook Troll + Sport AY 2018"
output:
  html_notebook:
    theme: united
    toc: yes
editor_options: 
  chunk_output_type: inline
---

# Introduction

## Goals & Objectives

The goal of this R Notebook is to analyze Chinook salmon mixtures from SEAK troll, sport, and THA fisheries for AY 2018. The individuals mixtures are indicated below by fishery:

  * Troll
    + Early Winter
        - NO
        - SONISI
    + Late Winter
        - NO
        - SONISI
    + Spring 1 (May)
        - 10145 - 200 fish
        - 10350 - 200 fish
        - 11341 - 200 fish
    + Spring 2 (June)
        - 10145 - 200 fish
        - 10350 - 200 fish
        - 11301 - 200 fish
        - 11341 - 200 fish
        - 11362 - 200 fish
    + Spring overall
        - 11330 - 100 fish
        - 18310 - 100 fish
    + Summer 1
        - NO
        - SO
        - NI
        - SI
    + Summer 2
        - NO
        - SO
        - NI
        - SI
  * Sport
    + Outside
        - Through BW 13
        - After BW 13
    + Petersburg-Wrangell (PBG-WRN)
    + Juneau (JNU)
    + Ketchikan (KTN)
    + Sitka (SIT)
    + Craig (CRG)
  * THA
    + 10195 (Neets Bay)
        - SW 18-23
        - SW 24
        - SW 25-27
    + 10735 (Anita Bay)
        - SW 20-21
        - SW 22
        - SW 23
        - SW 24
        - SW 25-30

We are going to run everything for 33 reporting groups and then summarise from there for whoever needs it.

## Outline

This R Notebook will:

1) Import mixture genotypes
2) Join ASL
3) Define mixture strata
3) Data QA
4) Create *BAYES* files
5) Summarize *BAYES* results
6) Output tables

## Setup

Load *GCL-R-Functions* and all necessary packages.
```{r setup, message=FALSE, results='hide'}
source("~/../R/Functions.GCL.R")
library(tidyverse)
library(lubridate)

.username <- "krshedd"
.password <- ""
```

Read in those objects and `LocusControl`
```{r load_objects}
load_objects("../Objects/")
```


# Winter troll: import mixture genotypes

Read in genotypes from *LOKI* as `.gcl` objects. Save in directory.
```{r winter_loki}
# origins_sillys <- c("KTROL17EW", "KTROL18LW", "KTROL18SP", "KTROL18SU", "KSPORT18", "KTROL18THA", "KGILL18THA", "KSEIN18THA", "KSEIN18CR")
winter_2018_sillys <- c("KTROL17EW", "KTROL18LW")
LOKI2R_GAPS.GCL(sillyvec = winter_2018_sillys, username = .username, password = .password)
rm(.username, .password)

sapply(winter_2018_sillys, function(silly) {get(paste0(silly, ".gcl"))$n} )

save_sillys(sillyvec = winter_2018_sillys, path = "../Genotypes/original")
save_objects(objects = c("winter_2018_sillys"), path = "../Objects/")
```

# Join ASL

## Winter Troll

Read in the troll ASL data.
```{r troll_asl, message=FALSE}
(troll_ASL <- read_csv(file = "../ASL Data/20190204_troll_2017_2018_Detailed ASL Samples.csv") %>% 
   select(`Sample Date`, `Stat Week`, `Port Code`, `Gear`, `District`, `Dna Specimen No`, `Cwt Strap Tag No`, `Gear Code`, `Harvest Code`))

# Any duplicate Dna Specimen No?
table(table(troll_ASL$`Dna Specimen No`, useNA = "always"), useNA = "always")
```

Shit, it looks like we have some duplicate Dna Specimen No (34 to be precise).
```{r asl_duplicates}
asl_duplicates <- troll_ASL %>% 
  group_by(`Dna Specimen No`) %>% 
  summarise(n = n()) %>% 
  filter(n > 1) %>% 
  pull(`Dna Specimen No`)

troll_ASL %>% 
  filter(`Dna Specimen No` %in% asl_duplicates) %>% 
  arrange(`Dna Specimen No`)
```

Are any of these fish in our winter troll samples?
```{r asl_duplicates_winter_troll}
early_winter_samples <- KTROL17EW.gcl$attributes %>% 
  mutate(`Dna Specimen No` = as.integer(paste0(str_sub(DNA_TRAY_CODE, 7, 10), str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")))) %>% 
  pull(`Dna Specimen No`)

any(early_winter_samples %in% asl_duplicates)

late_winter_samples <- KTROL18LW.gcl$attributes %>% 
  mutate(`Dna Specimen No` = as.integer(paste0(str_sub(DNA_TRAY_CODE, 7, 10), str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")))) %>% 
  pull(`Dna Specimen No`)

any(late_winter_samples %in% asl_duplicates)
```

Cool, none of our ASL duplicate Dna Specimen No are in there. Now verify that all winter samples are in the ASL data.
```{r winter_in_asl}
all(early_winter_samples %in% troll_ASL$`Dna Specimen No`)
all(late_winter_samples %in% troll_ASL$`Dna Specimen No`)
```

Which early winter sample(s) are missing?
```{r early_winter_missing}
# Which sample is missing from ASL?
(early_missing <- setdiff(early_winter_samples, troll_ASL$`Dna Specimen No`))

# Does that WGC exist?
troll_ASL %>% 
  mutate(WGC_4char = str_sub(`Dna Specimen No`, 1, 4)) %>% 
  filter(WGC_4char == str_sub(early_missing, 1, 4))

# Did we extract this fish?
EW_torun_ASL.df %>% 
  filter(`Dna Specimen No` == early_missing)

# Nope, we did not extract this fish
setdiff(early_winter_samples, EW_torun_ASL.df$`Dna Specimen No`)

# What fish did we attempt to extract, but not get?
setdiff(EW_torun_ASL.df$`Dna Specimen No`, early_winter_samples)
```

WTF, what is the deal with this fish? Probably mixed up with 549901
```{r early_winter_missing_cont}
KTROL17EW.gcl$attributes %>% 
  mutate(`Dna Specimen No` = as.integer(paste0(str_sub(DNA_TRAY_CODE, 7, 10), str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")))) %>% 
  filter(`Dna Specimen No` %in% early_missing)

troll_ASL %>% 
  filter(`Dna Specimen No` == 549901)
```

I went out to the warehouse to pull the WGC and confirmed that the ASL data is incorrect, the card Dna Specimen No should be 459901, not 549901

```{r early_winter_missing_fix}
troll_ASL <- troll_ASL %>% 
  mutate(`Dna Specimen No` = case_when(`Dna Specimen No` == 549901 ~ 459901,
                                       TRUE ~ `Dna Specimen No`))
```

Now that we've resolved our ASL discrepancy, join with attributes to get quadrant level information.
```{r join_winter_asl}
# Join ASL with attributes table
# Early Winter
KTROL17EW.gcl$attributes <- KTROL17EW.gcl$attributes %>% 
  mutate(`Dna Specimen No` = as.integer(paste0(str_sub(DNA_TRAY_CODE, 7, 10), str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")))) %>% 
  left_join(troll_ASL, by = "Dna Specimen No")

# Late Winter
KTROL18LW.gcl$attributes <- KTROL18LW.gcl$attributes %>% 
  mutate(`Dna Specimen No` = as.integer(paste0(str_sub(DNA_TRAY_CODE, 7, 10), str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")))) %>% 
  left_join(troll_ASL, by = "Dna Specimen No")
```

How many fish per district?
```{r winter_district_counts}
KTROL17EW.gcl$attributes %>% 
  count(District)

KTROL18LW.gcl$attributes %>% 
  count(District)
```

# Define mixture strata

Winter mixtures are each quadrant by itself.

Create early winter mixtures.
```{r early_winter_define_mixtures}
EWintNO_2018.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTROL17EW", attribute = "District", matching = 171)), nm = "KTROL17EW")
PoolCollections.GCL(collections = "KTROL17EW", loci = GAPSLoci_reordered, IDs = EWintNO_2018.vials, newname = "EWintNO_2018")

EWintSO_2018.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTROL17EW", attribute = "District", matching = 172)), nm = "KTROL17EW")
PoolCollections.GCL(collections = "KTROL17EW", loci = GAPSLoci_reordered, IDs = EWintSO_2018.vials, newname = "EWintSO_2018")

EWintNI_2018.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTROL17EW", attribute = "District", matching = 173)), nm = "KTROL17EW")
PoolCollections.GCL(collections = "KTROL17EW", loci = GAPSLoci_reordered, IDs = EWintNI_2018.vials, newname = "EWintNI_2018")

EWintSI_2018.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTROL17EW", attribute = "District", matching = 174)), nm = "KTROL17EW")
PoolCollections.GCL(collections = "KTROL17EW", loci = GAPSLoci_reordered, IDs = EWintSI_2018.vials, newname = "EWintSI_2018")

sapply(grep(pattern = "EWint", objects(pattern = "\\.gcl"), value = TRUE), function(silly) {get(silly)$n})
```

Create late winter mixtures.
```{r late_winter_define_mixtures}
LWintNO_2018.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTROL18LW", attribute = "District", matching = 171)), nm = "KTROL18LW")
PoolCollections.GCL(collections = "KTROL18LW", loci = GAPSLoci_reordered, IDs = LWintNO_2018.vials, newname = "LWintNO_2018")

LWintSO_2018.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTROL18LW", attribute = "District", matching = 172)), nm = "KTROL18LW")
PoolCollections.GCL(collections = "KTROL18LW", loci = GAPSLoci_reordered, IDs = LWintSO_2018.vials, newname = "LWintSO_2018")

LWintNI_2018.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTROL18LW", attribute = "District", matching = 173)), nm = "KTROL18LW")
PoolCollections.GCL(collections = "KTROL18LW", loci = GAPSLoci_reordered, IDs = LWintNI_2018.vials, newname = "LWintNI_2018")

LWintSI_2018.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTROL18LW", attribute = "District", matching = 174)), nm = "KTROL18LW")
PoolCollections.GCL(collections = "KTROL18LW", loci = GAPSLoci_reordered, IDs = LWintSI_2018.vials, newname = "LWintSI_2018")

sapply(grep(pattern = "LWint", objects(pattern = "\\.gcl"), value = TRUE), function(silly) {get(silly)$n})
```

Save genotypes for winter strata.
```{r save_winter_strata_genotypes}
if(!dir.exists("../Genotypes/strata")) {dir.create("../Genotypes/strata")}

winter_2018_mixnames <- c(paste0("EWint", c("NO", "SO", "NI", "SI"), "_2018"), 
                          paste0("LWint", c("NO", "SO", "NI", "SI"), "_2018"))

save_objects(objects = "winter_2018_mixnames", path = "../Objects/")
save_sillys(sillyvec = winter_2018_mixnames, path = "../Genotypes/strata/")
```

# Data QA

Standard data QA:

  * Remove fish missing <80% genotypes
  * Remove duplicates (>95% genotype concordance)

```{r QA}
# original sample sizes
winter_2018_sample_sizes <- tibble(silly = winter_2018_mixnames,
                                   genotyped = sapply(winter_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# missing
winter_2018_missing <- RemoveIndMissLoci.GCL(sillyvec = winter_2018_mixnames, proportion = 0.8)
save_objects("winter_2018_missing", "../Objects/")

winter_2018_sample_sizes <- winter_2018_sample_sizes %>% 
  mutate(missing = genotyped - sapply(winter_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# duplicate
winter_2018_duplicates <- CheckDupWithinSilly.GCL(sillyvec = winter_2018_mixnames, loci = GAPSLoci_reordered, quantile = NULL, minproportion = 0.95)
(winter_2018_duplicates_summary <- sapply(winter_2018_mixnames, function(x) {winter_2018_duplicates[[x]]$report}))
save_objects("winter_2018_duplicates_summary", "../Objects/")

winter_2018_duplciates_removed <- RemoveDups.GCL(dupcheck = winter_2018_duplicates)

winter_2018_sample_sizes <- winter_2018_sample_sizes %>% 
  mutate(duplicate = genotyped - missing - sapply(winter_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# final
winter_2018_sample_sizes <- winter_2018_sample_sizes %>% 
  mutate(final = sapply(winter_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))
winter_2018_sample_sizes
save_objects("winter_2018_sample_sizes", "../Objects/")

write_csv(winter_2018_sample_sizes, "../Tables/winter_2018_sample_sizes.csv")
```

Save post-QA genotypes
```{r post_QA}
if(!dir.exists("../Genotypes/strata_postQA/")) {dir.create("../Genotypes/strata_postQA/")}
save_sillys(sillyvec = winter_2018_mixnames, path = "../Genotypes/strata_postQA")
```

# Create *BAYES* files

## Directory setup

First need to set up *BAYES* directory structure and copy over baseline file and *BAYES* objects. This was already done when we ran TBR.
```{r BAYES_setup, results='hide'}
# dir.create(path = "../BAYES")
# sapply(c("Baseline", "Control", "Mixture", "Output"), function(folder) {dir.create(path = paste("../BAYES", folder, sep = "/"))} )
# 
# file.copy(from = "V:/Analysis/1_SEAK/Chinook/Baseline/GAPS3.0/Objects/SEAKPops357.txt", to = "../Objects")
# file.copy(from = "V:/Analysis/1_SEAK/Chinook/Baseline/GAPS3.0/Objects/bayesfortran_357.txt", to = "../Objects")
# file.copy(from = "V:/Analysis/1_SEAK/Chinook/Baseline/GAPS3.0/BAYES/Baseline/GAPS357pops13loci.bse", to = "../BAYES/Baseline")
# file.copy(from = "V:/Analysis/4_Westward/Sockeye/KMA Commercial Harvest 2014-2016/Mixtures/Objects/WASSIPSockeyeSeeds.txt", to = "../Objects")
# 
# TBR_mixnames <- setNames(c("D108Gill_2018", "D111Gill_2018", "D111Sport_2018"), TBR_sillys)
# save_objects("TBR_mixnames", "../Objects/")
# load_objects("../Objects/")
```

## Create mixtures

Save the fortran format and create TBR *BAYES* mixture files. This was already done when we ran TBR.
```{r BAYES_mixtures}
# mixfortran <- CreateMixture.GCL(sillys = TBR_sillys[1], loci = GAPSLoci_reordered, IDs = NULL, mixname = TBR_mixnames[TBR_sillys[1]], dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
# save_objects("mixfortran", "../Objects/")

sapply(winter_2018_mixnames, function(mix) {
  CreateMixture.GCL(sillys = mix, loci = GAPSLoci_reordered, IDs = NULL, mixname = mix, dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
} )
```

## Create priors

New this year, I will be analyzing **ALL** Chinook mixtures with the full 33 reporting groups. However, since I ran last year's troll mixtures for just the 26 reporting groups, I will have to mess with the priors a bit. Also a new wrinkle because we've previously ran NISISO together for Early and Late Winter. I think to keep things simple, I'll use the previous year's NISISO estimate for the prior for each of those respective quadrants (NI, SI, and SO)
```{r read_2017_estimates}
EWint_2017_26RG_EstimatesStats <- dget("../../SEAK17/Estimates objects/EWint_2017_26RG_EstimatesStats.txt")
LWint_2017_26RG_EstimatesStats <- dget("../../SEAK17/Estimates objects/LWint_2017_26RG_EstimatesStats.txt")

(winter_2017_means <- sapply(c(EWint_2017_26RG_EstimatesStats, LWint_2017_26RG_EstimatesStats), function(mix) {mix[, "mean"]}))
```

My plan is to keep the same prior for the 26 groups and then spread out the prior evenly across all other 33 reporting groups.
```{r setup_2018_priors}
# Convert from 26RG to 33RG
winter_2017_means_33RG <- apply(winter_2017_means, 2, function(mix) {mix[GroupVec33RG_to26RG] / table(GroupVec33RG_to26RG)[GroupVec33RG_to26RG]} )
rownames(winter_2017_means_33RG) <- GroupNames33

# Duplicate NISISO to NI, SI, SO
winter_2017_means_33RG <- winter_2017_means_33RG[, c(1, 2, 2, 2, 3, 4, 4, 4)]

# Fix dimnames
colnames(winter_2017_means_33RG) <- winter_2018_mixnames

# Verify
apply(winter_2017_means_33RG, 2, sum)
```

Now create 2018 priors.
```{r create_2018_priors}
winter_2018_priors <- apply(winter_2017_means_33RG, 2, function(mix) {
  Prior.GCL(groupvec = GroupVec33RG_357, groupweights = mix, minval = 0.01)
} )
colnames(winter_2018_priors) <- winter_2018_mixnames
save_objects("winter_2018_priors", "../Objects/")
```

## Create control files

Now that we have priors, just need to create *BAYES* control files.
```{r BAYES_control}
sapply(winter_2018_mixnames, function(mix) {
  CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = mix, basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                        nchains = 5, groupvec = GroupVec33RG_357, priorvec = winter_2018_priors[, mix], initmat = GAPS357PopsInits, 
                        dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                        basefortran = bayesfortran_357, switches = "F T F T T T F")
} )

```

## Create output directories

```{r BAYES_output}
sapply(winter_2018_mixnames, function(mix) {dir.create(paste0("../BAYES/Output/", mix))} )
```

# Summarize *BAYES* results

Summarize results for both the full 33 reporting groups, the 5 TBR groups, 3 TBR groups, and 2 TBR groups.

## 33 reporting groups

Create standard summary and save.
```{r winter_BAYES_summarise_33RG}
# full 33 reporting groups
EWint_2018_33RG_EstimatesStats <- 
  CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, maindir = "../BAYES/Output", mixvec = winter_2018_mixnames[1:4],
                               prior = "", ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1, PosteriorOutput = FALSE)

LWint_2018_33RG_EstimatesStats <- 
  CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, maindir = "../BAYES/Output", mixvec = winter_2018_mixnames[5:8],
                               prior = "", ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1, PosteriorOutput = FALSE)

# dir.create("../Estimates objects")
save_objects(c("EWint_2018_33RG_EstimatesStats", "LWint_2018_33RG_EstimatesStats"), "../Estimates objects")
```

Make in to tall tibble.
```{r winter_BAYES_33RG_tibble}
# make in to a tidy tibble (tall)
winter_2018_33RG_estimates.tdy <- 
  bind_rows(
    lapply(winter_2018_mixnames, function(mix) {  # loop over mixture names
      c(EWint_2018_33RG_EstimatesStats, LWint_2018_33RG_EstimatesStats)[[mix]] %>%  # for each matrix
        as_tibble(rownames = "group") %>%  # make tibble with rownames as group
        mutate(mixname = mix) %>%  # make column for mixname
        mutate(n_group = n_distinct(group))  # make column for number of groups
    } )
  ) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("mix", "year"), sep = "_", remove = FALSE) %>%  # extract mixture and year
  separate(mix, c("fishery", "quadrant"), sep = 5) %>%  # extract district and gear
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames33))  # factor for ordering

save_objects(c("winter_2018_33RG_estimates.tdy"), "../Estimates objects")
```

## Stratified estimate for 33 RG

Generate All Quad estimates for Early and Late Winter.
```{r winter_stratified_33RG}
EWint_2018_33RG_StratifiedEstimatesStats <- 
  StratifiedEstimator.GCL(groupvec = 1:33, groupnames = GroupNames33, maindir = "../BAYES/Output/", mixvec = winter_2018_mixnames[1:4], catchvec = c(4501, 86, 1262, 1549), newname = "EWintAllQuad", ext = "RGN", nchains = 5, xlxs = FALSE, PosteriorOutput = FALSE)

LWint_2018_33RG_StratifiedEstimatesStats <- 
  StratifiedEstimator.GCL(groupvec = 1:33, groupnames = GroupNames33, maindir = "../BAYES/Output/", mixvec = winter_2018_mixnames[5:8], catchvec = c(1664, 362, 903, 1640), newname = "LWintAllQuad", ext = "RGN", nchains = 5, xlxs = FALSE, PosteriorOutput = FALSE)

save_objects(c("EWint_2018_33RG_StratifiedEstimatesStats", "LWint_2018_33RG_StratifiedEstimatesStats"), "../Estimates objects")
```

Make in to tall tibble.
```{r winter_stratified_33RG_tibble}
# make in to a tidy tibble (tall)
winter_2018_33RG_stratified_estimates.tdy <- 
  bind_rows(
    lapply(c("EWintAllQuad_2018", "LWintAllQuad_2018"), function(mix) {  # loop over mixture names
      list("EWintAllQuad_2018" = EWint_2018_33RG_StratifiedEstimatesStats, 
           "LWintAllQuad_2018" = LWint_2018_33RG_StratifiedEstimatesStats)[[mix]] %>%  # for each matrix
        as_tibble(rownames = "group") %>%  # make tibble with rownames as group
        mutate(mixname = mix) %>%  # make column for mixname
        mutate(n_group = n_distinct(group))  # make column for number of groups
    } )
  ) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("mix", "year"), sep = "_", remove = FALSE) %>%  # extract mixture and year
  separate(mix, c("fishery", "quadrant"), sep = 5) %>%  # extract district and gear
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames33))  # factor for ordering

save_objects(c("winter_2018_33RG_stratified_estimates.tdy"), "../Estimates objects")
```

# THA: import mixture genotypes

Read in genotypes from *LOKI* as `.gcl` objects. Save in directory.
```{r THA_loki}
# origins_sillys <- c("KTROL17EW", "KTROL18LW", "KTROL18SP", "KTROL18SU", "KSPORT18", "KTROL18THA", "KGILL18THA", "KSEIN18THA")
THA_2018_sillys <- c("KTROL18THA", "KGILL18THA", "KSEIN18THA")
LOKI2R_GAPS.GCL(sillyvec = THA_2018_sillys, username = .username, password = .password)
rm(.username, .password)

sapply(THA_2018_sillys, function(silly) {get(paste0(silly, ".gcl"))$n} )

save_sillys(sillyvec = THA_2018_sillys, path = "../Genotypes/original")
save_objects(objects = c("THA_2018_sillys"), path = "../Objects/")
```

# Join ASL

## THA

Read in the THA ASL data.
```{r THA_asl, message=FALSE}
(THA_ASL <- read_csv(file = "../ASL Data/20181213_terminal_Harvest - Detailed ASL Samples.csv") %>% 
   select(`Sample Date`, `Stat Week`, `Port Code`, `Gear`, `Stat Area`, `Dna Specimen No`, `Cwt Strap Tag No`, `Gear Code`, `Harvest Code`))

# Any duplicate Dna Specimen No?
table(table(THA_ASL$`Dna Specimen No`, useNA = "always"), useNA = "always")
```

Nope, no duplicates, great news.
```{r asl_duplicates_THA_troll}
THA_samples <- bind_rows(KTROL18THA.gcl$attributes, KGILL18THA.gcl$attributes, KSEIN18THA.gcl$attributes) %>% 
  mutate(`Dna Specimen No` = as.integer(paste0(str_sub(DNA_TRAY_CODE, 7, 10), str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")))) %>% 
  pull(`Dna Specimen No`)
```

Cool, none of our ASL duplicate Dna Specimen No are in there. Now verify that all winter samples are in the ASL data.
```{r THA_in_asl}
all(THA_samples %in% THA_ASL$`Dna Specimen No`)
```

Now that we've verified that all genotyped samples are in the ASL data, pool all sillys into one THA silly, then join with attributes to get quadrant level information.
```{r join_THA_asl}
# Pool
PoolCollections.GCL(collections = THA_2018_sillys, loci = GAPSLoci_reordered, newname = "KTHA18")

# Join ASL with attributes table
KTHA18.gcl$attributes <- KTHA18.gcl$attributes %>% 
  mutate(`Dna Specimen No` = as.integer(paste0(str_sub(DNA_TRAY_CODE, 7, 10), str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")))) %>% 
  left_join(THA_ASL, by = "Dna Specimen No")
```

How many fish per stat area by gear and stat week?
```{r THA_stat_area_counts}
KTHA18.gcl$attributes %>% 
  count(Gear, `Stat Week`, `Stat Area`) %>% 
  spread(`Stat Week`, n) %>% 
  arrange(`Stat Area`)
```

Create a variable for mixture for ease of pooling into separate mixtures.
```{r THA_attributes_mixture}
KTHA18.gcl$attributes <- KTHA18.gcl$attributes %>% 
  mutate(mixture = case_when(`Stat Area` == "101-95" & `Stat Week` %in% 18:23 ~ "neets_sw18_23",
                             `Stat Area` == "101-95" & `Stat Week` %in% 24 ~ "neets_sw24",
                             `Stat Area` == "101-95" & `Stat Week` %in% 25:27 ~ "neets_sw25_27",
                             `Stat Area` == "107-35" & `Stat Week` %in% 20:21 ~ "anita_sw20_21",
                             `Stat Area` == "107-35" & `Stat Week` %in% 22 ~ "anita_sw22",
                             `Stat Area` == "107-35" & `Stat Week` %in% 23 ~ "anita_sw23",
                             `Stat Area` == "107-35" & `Stat Week` %in% 24 ~ "anita_sw24",
                             `Stat Area` == "107-35" & `Stat Week` %in% 25:30 ~ "anita_sw25_30"))

KTHA18.gcl$attributes %>% 
  count(mixture)
```


# Define mixture strata

THA mixtures are each stat area and stat week. Each mixture has ~ 100 fish. We are doing 3 mixtures for Neets Bay (101-95) and 5 mixtures for Anita Bay (107-35).

  * THA
    + 10195 (Neets Bay)
        - SW 18-23
        - SW 24
        - SW 25-27
    + 10735 (Anita Bay)
        - SW 20-21
        - SW 22
        - SW 23
        - SW 24
        - SW 25-30

Create THA mixtures.
```{r THA_define_mixtures}
Neets_SW18_23.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTHA18", attribute = "mixture", matching = "neets_sw18_23")), nm = "KTHA18")
PoolCollections.GCL(collections = "KTHA18", loci = GAPSLoci_reordered, IDs = Neets_SW18_23.vials, newname = "Neets_SW18_23")

Neets_SW24.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTHA18", attribute = "mixture", matching = "neets_sw24")), nm = "KTHA18")
PoolCollections.GCL(collections = "KTHA18", loci = GAPSLoci_reordered, IDs = Neets_SW24.vials, newname = "Neets_SW24")

Neets_SW25_27.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTHA18", attribute = "mixture", matching = "neets_sw25_27")), nm = "KTHA18")
PoolCollections.GCL(collections = "KTHA18", loci = GAPSLoci_reordered, IDs = Neets_SW25_27.vials, newname = "Neets_SW25_27")

Anita_SW20_21.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTHA18", attribute = "mixture", matching = "anita_sw20_21")), nm = "KTHA18")
PoolCollections.GCL(collections = "KTHA18", loci = GAPSLoci_reordered, IDs = Anita_SW20_21.vials, newname = "Anita_SW20_21")

Anita_SW22.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTHA18", attribute = "mixture", matching = "anita_sw22")), nm = "KTHA18")
PoolCollections.GCL(collections = "KTHA18", loci = GAPSLoci_reordered, IDs = Anita_SW22.vials, newname = "Anita_SW22")

Anita_SW23.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTHA18", attribute = "mixture", matching = "anita_sw23")), nm = "KTHA18")
PoolCollections.GCL(collections = "KTHA18", loci = GAPSLoci_reordered, IDs = Anita_SW23.vials, newname = "Anita_SW23")

Anita_SW24.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTHA18", attribute = "mixture", matching = "anita_sw24")), nm = "KTHA18")
PoolCollections.GCL(collections = "KTHA18", loci = GAPSLoci_reordered, IDs = Anita_SW24.vials, newname = "Anita_SW24")

Anita_SW25_30.vials <- setNames(object = list(AttributesToIDs.GCL(silly = "KTHA18", attribute = "mixture", matching = "anita_sw25_30")), nm = "KTHA18")
PoolCollections.GCL(collections = "KTHA18", loci = GAPSLoci_reordered, IDs = Anita_SW25_30.vials, newname = "Anita_SW25_30")

sapply(grep(pattern = "_SW", objects(pattern = "\\.gcl"), value = TRUE), function(silly) {get(silly)$n})
```

Save genotypes for THA strata.
```{r save_THA_strata_genotypes}
if(!dir.exists("../Genotypes/strata")) {dir.create("../Genotypes/strata")}

THA_2018_mixnames <- gsub(pattern = ".gcl", replacement = '', x = grep(pattern = "_SW", objects(pattern = "\\.gcl"), value = TRUE))

save_objects(objects = "THA_2018_mixnames", path = "../Objects/")
save_sillys(sillyvec = THA_2018_mixnames, path = "../Genotypes/strata/")
```

# Data QA

Standard data QA:

  * Remove fish missing <80% genotypes
  * Remove duplicates (>95% genotype concordance)

```{r THA_QA}
# original sample sizes
THA_2018_sample_sizes <- tibble(silly = THA_2018_mixnames,
                                genotyped = sapply(THA_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# missing
THA_2018_missing <- RemoveIndMissLoci.GCL(sillyvec = THA_2018_mixnames, proportion = 0.8)
save_objects("THA_2018_missing", "../Objects/")

THA_2018_sample_sizes <- THA_2018_sample_sizes %>% 
  mutate(missing = genotyped - sapply(THA_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# duplicate
THA_2018_duplicates <- CheckDupWithinSilly.GCL(sillyvec = THA_2018_mixnames, loci = GAPSLoci_reordered, quantile = NULL, minproportion = 0.95)
(THA_2018_duplicates_summary <- sapply(THA_2018_mixnames, function(x) {THA_2018_duplicates[[x]]$report}))
save_objects("THA_2018_duplicates_summary", "../Objects/")

THA_2018_duplciates_removed <- RemoveDups.GCL(dupcheck = THA_2018_duplicates)

THA_2018_sample_sizes <- THA_2018_sample_sizes %>% 
  mutate(duplicate = genotyped - missing - sapply(THA_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# final
THA_2018_sample_sizes <- THA_2018_sample_sizes %>% 
  mutate(final = sapply(THA_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))
THA_2018_sample_sizes
save_objects("THA_2018_sample_sizes", "../Objects/")

write_csv(THA_2018_sample_sizes, "../Tables/THA_2018_sample_sizes.csv")
```

Save post-QA genotypes
```{r THA_post_QA}
if(!dir.exists("../Genotypes/strata_postQA/")) {dir.create("../Genotypes/strata_postQA/")}
save_sillys(sillyvec = THA_2018_mixnames, path = "../Genotypes/strata_postQA")
```

# Create *BAYES* files

## Directory setup

First need to set up *BAYES* directory structure and copy over baseline file and *BAYES* objects. This was already done when we ran TBR.
```{r THA_BAYES_setup, results='hide'}
# dir.create(path = "../BAYES")
# sapply(c("Baseline", "Control", "Mixture", "Output"), function(folder) {dir.create(path = paste("../BAYES", folder, sep = "/"))} )
# 
# file.copy(from = "V:/Analysis/1_SEAK/Chinook/Baseline/GAPS3.0/Objects/SEAKPops357.txt", to = "../Objects")
# file.copy(from = "V:/Analysis/1_SEAK/Chinook/Baseline/GAPS3.0/Objects/bayesfortran_357.txt", to = "../Objects")
# file.copy(from = "V:/Analysis/1_SEAK/Chinook/Baseline/GAPS3.0/BAYES/Baseline/GAPS357pops13loci.bse", to = "../BAYES/Baseline")
# file.copy(from = "V:/Analysis/4_Westward/Sockeye/KMA Commercial Harvest 2014-2016/Mixtures/Objects/WASSIPSockeyeSeeds.txt", to = "../Objects")
# 
# TBR_mixnames <- setNames(c("D108Gill_2018", "D111Gill_2018", "D111Sport_2018"), TBR_sillys)
# save_objects("TBR_mixnames", "../Objects/")
# load_objects("../Objects/")
```

## Create mixtures

Save the fortran format and create TBR *BAYES* mixture files. This was already done when we ran TBR.
```{r THA_BAYES_mixtures}
# mixfortran <- CreateMixture.GCL(sillys = TBR_sillys[1], loci = GAPSLoci_reordered, IDs = NULL, mixname = TBR_mixnames[TBR_sillys[1]], dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
# save_objects("mixfortran", "../Objects/")

sapply(THA_2018_mixnames, function(mix) {
  CreateMixture.GCL(sillys = mix, loci = GAPSLoci_reordered, IDs = NULL, mixname = mix, dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
} )
```

## Create priors

New this year, I will be analyzing **ALL** Chinook mixtures with the full 33 reporting groups. Also a new wrinkle because we've never ran any THA mixtures, I'm not entirely sure what to use as a good prior. After talking with Sara, we agreed to do a rolling prior. For the first mixture for each area, we agreed to put 90% of the prior weight on the reporting group for the brood source released in each location (Neets-Chickamin and Anita-Andrew) and spread the rest out among all other reporting groups. Not ideal, but better than a group flat prior or anything else we could think of.

Now create 2018 priors.
```{r THA_create_2018_priors}
# Put prior weight on Andrew Creek for Anita (Andrew brood source)
Anita_SW20_21_2018_prior <- Prior.GCL(groupvec = GroupVec33RG_357, groupweights = as.numeric(GroupNames33 == "Andrew"), minval = 0.003125) # this puts 90% prior weight on Andrew

# Put prior weight on SSEAK for Neets (Chickamin brood source)
Neets_SW18_23_2018_prior <- Prior.GCL(groupvec = GroupVec33RG_357, groupweights = as.numeric(GroupNames33 == "SSEAK"), minval = 0.003125) # this puts 90% prior weight on SSEAK

save_objects(c("Anita_SW20_21_2018_prior", "Neets_SW18_23_2018_prior"), "../Objects/")
```

## Create control files

Now that we have priors, just need to create *BAYES* control files for the first Neets and Anita runs.
```{r THA_BAYES_control}
CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = "Anita_SW20_21", basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                      nchains = 5, groupvec = GroupVec33RG_357, priorvec = Anita_SW20_21_2018_prior, initmat = GAPS357PopsInits, 
                      dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                      basefortran = bayesfortran_357, switches = "F T F T T T F")

CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = "Neets_SW18_23", basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                      nchains = 5, groupvec = GroupVec33RG_357, priorvec = Neets_SW18_23_2018_prior, initmat = GAPS357PopsInits, 
                      dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                      basefortran = bayesfortran_357, switches = "F T F T T T F")
```

## Create output directories

```{r THA_BAYES_output}
sapply(THA_2018_mixnames, function(mix) {dir.create(paste0("../BAYES/Output/", mix))} )
```

## Summarize *BAYES* output for rolling prior

Need to quickly summarize the output from Anita_SW20_21 and Neets_SW18_23 for rolling prior.
```{r THA_rolling_prior_1}
Anita_SW20_21_estimates_33RG <- CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, 
                                                             maindir = "../BAYES/Output/", mixvec = THA_2018_mixnames[1],
                                                             prior = '', ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1,
                                                             PosteriorOutput = FALSE)

Anita_SW22_2018_prior <- Prior.GCL(groupvec = GroupVec33RG_357, groupweights = Anita_SW20_21_estimates_33RG[[1]][, "mean"], minval = 0.01)
save_objects(objects = "Anita_SW22_2018_prior", path = "../Objects/")

CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = "Anita_SW22", basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                      nchains = 5, groupvec = GroupVec33RG_357, priorvec = Anita_SW22_2018_prior, initmat = GAPS357PopsInits, 
                      dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                      basefortran = bayesfortran_357, switches = "F T F T T T F")


Neets_SW18_23_estimates_33RG <- CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, 
                                                             maindir = "../BAYES/Output/", mixvec = THA_2018_mixnames[6],
                                                             prior = '', ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1,
                                                             PosteriorOutput = FALSE)

Neets_SW24_2018_prior <- Prior.GCL(groupvec = GroupVec33RG_357, groupweights = Neets_SW18_23_estimates_33RG[[1]][, "mean"], minval = 0.01)
save_objects(objects = "Neets_SW24_2018_prior", path = "../Objects/")

CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = "Neets_SW24", basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                      nchains = 5, groupvec = GroupVec33RG_357, priorvec = Neets_SW24_2018_prior, initmat = GAPS357PopsInits, 
                      dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                      basefortran = bayesfortran_357, switches = "F T F T T T F")
```

Need to quickly summarize the output from Anita_SW22 and Neets_SW24 for rolling prior.
```{r THA_rolling_prior_2}
Anita_SW22_estimates_33RG <- CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, 
                                                          maindir = "../BAYES/Output/", mixvec = THA_2018_mixnames[2],
                                                          prior = '', ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1,
                                                          PosteriorOutput = FALSE)

Anita_SW23_2018_prior <- Prior.GCL(groupvec = GroupVec33RG_357, groupweights = Anita_SW22_estimates_33RG[[1]][, "mean"], minval = 0.01)
save_objects(objects = "Anita_SW23_2018_prior", path = "../Objects/")

CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = "Anita_SW23", basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                      nchains = 5, groupvec = GroupVec33RG_357, priorvec = Anita_SW23_2018_prior, initmat = GAPS357PopsInits, 
                      dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                      basefortran = bayesfortran_357, switches = "F T F T T T F")


Neets_SW24_estimates_33RG <- CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, 
                                                          maindir = "../BAYES/Output/", mixvec = THA_2018_mixnames[7],
                                                          prior = '', ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1,
                                                          PosteriorOutput = FALSE)

Neets_SW25_27_2018_prior <- Prior.GCL(groupvec = GroupVec33RG_357, groupweights = Neets_SW24_estimates_33RG[[1]][, "mean"], minval = 0.01)
save_objects(objects = "Neets_SW25_27_2018_prior", path = "../Objects/")

CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = "Neets_SW25_27", basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                      nchains = 5, groupvec = GroupVec33RG_357, priorvec = Neets_SW25_27_2018_prior, initmat = GAPS357PopsInits, 
                      dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                      basefortran = bayesfortran_357, switches = "F T F T T T F")
```

Need to quickly summarize the output from Anita_SW23 for rolling prior.
```{r THA_rolling_prior_3}
Anita_SW23_estimates_33RG <- CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, 
                                                          maindir = "../BAYES/Output/", mixvec = THA_2018_mixnames[3],
                                                          prior = '', ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1,
                                                          PosteriorOutput = FALSE)

Anita_SW24_2018_prior <- Prior.GCL(groupvec = GroupVec33RG_357, groupweights = Anita_SW23_estimates_33RG[[1]][, "mean"], minval = 0.01)
save_objects(objects = "Anita_SW24_2018_prior", path = "../Objects/")

CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = "Anita_SW24", basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                      nchains = 5, groupvec = GroupVec33RG_357, priorvec = Anita_SW24_2018_prior, initmat = GAPS357PopsInits, 
                      dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                      basefortran = bayesfortran_357, switches = "F T F T T T F")
```

Need to quickly summarize the output from Anita_SW24 for rolling prior.
```{r THA_rolling_prior_4}
Anita_SW24_estimates_33RG <- CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, 
                                                          maindir = "../BAYES/Output/", mixvec = THA_2018_mixnames[4],
                                                          prior = '', ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1,
                                                          PosteriorOutput = FALSE)

Anita_SW25_30_2018_prior <- Prior.GCL(groupvec = GroupVec33RG_357, groupweights = Anita_SW24_estimates_33RG[[1]][, "mean"], minval = 0.01)
save_objects(objects = "Anita_SW25_30_2018_prior", path = "../Objects/")

CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = "Anita_SW25_30", basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                      nchains = 5, groupvec = GroupVec33RG_357, priorvec = Anita_SW25_30_2018_prior, initmat = GAPS357PopsInits, 
                      dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                      basefortran = bayesfortran_357, switches = "F T F T T T F")
```

# Summarize *BAYES* results

Summarize results for both the full 33 reporting groups and the custom 5 THA reporting groups.

## 33 reporting groups

Create standard summary and tall tibble, save both.
```{r BAYES_summarise_THA_33RG}
# full 33 reporting groups
THA_2018_33RG_EstimatesStats <- 
  CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, maindir = "../BAYES/Output", mixvec = THA_2018_mixnames,
                               prior = "", ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1, PosteriorOutput = FALSE)

# make in to a tidy tibble (tall)
THA_2018_33RG_estimates.tdy <- 
  bind_rows(
    lapply(THA_2018_mixnames, function(mix) {  # loop over mixture names
      THA_2018_33RG_EstimatesStats[[mix]] %>%  # for each matrix
        as_tibble(rownames = "group") %>%  # make tibble with rownames as group
        mutate(mixname = mix) %>%  # make column for mixname
        mutate(n_group = n_distinct(group))  # make column for number of groups
    } )
  ) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("THA", "SW_range"), sep = "_SW", remove = FALSE) %>%  # extract mixture and year
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames33))  # factor for ordering

save_objects(c("THA_2018_33RG_EstimatesStats", "THA_2018_33RG_estimates.tdy"), "../Estimates objects")
```

## 5 THA reporting groups

Create standard summary and tall tibble, save both.
```{r BAYES_summarise_THA_5RG}
GroupNames5_THA <- c("Andrew", "TBR", "SSEAK", "Other SEAK", "Other")
GroupVec5RG_THA_33 <- c(4, 2, 4, 4, 2, 1, 2, 3, rep(5, 25))

THA_2018_5RG_EstimatesStats <- 
  CustomCombineBAYESOutput.GCL(groupvec = GroupVec5RG_THA_33, groupnames = GroupNames5_THA, maindir = "../BAYES/Output", 
                               mixvec = THA_2018_mixnames,
                               prior = "", ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1, PosteriorOutput = FALSE)

# make in to a tidy tibble (tall)
THA_2018_5RG_estimates.tdy <- 
  bind_rows(
    lapply(THA_2018_mixnames, function(mix) {  # loop over mixture names
      THA_2018_5RG_EstimatesStats[[mix]] %>%  # for each matrix
        as_tibble(rownames = "group") %>%  # make tibble with rownames as group
        mutate(mixname = mix) %>%  # make column for mixname
        mutate(n_group = n_distinct(group))  # make column for number of groups
    } )
  ) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("THA", "SW_range"), sep = "_SW", remove = FALSE) %>%  # extract mixture and year
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames5_THA))  # factor for ordering

save_objects(c("GroupNames5_THA", "GroupVec5RG_THA_33"), "../Objects")
save_objects(c("THA_2018_5RG_EstimatesStats", "THA_2018_5RG_estimates.tdy"), "../Estimates objects")
```

# Plot THA 5RG

```{r THA_plots}
THA_2018_5RG_estimates.tdy %>% 
  mutate(value = value * 100) %>% 
  spread(estimator, value) %>% 
  filter(THA == "Anita") %>% 
  ggplot(aes(x = SW_range, y = mean, group = group, fill = group)) +
  geom_col(width = 0.7, position = position_dodge(0.8)) +
  geom_errorbar(aes(ymin = `5%`, ymax = `95%`), width = 0.4, position = position_dodge(0.8)) +
  ylim(c(0, 100)) +
  ylab("Stock Composition (%)") +
  xlab("Stat Week Range") +
  guides(fill = guide_legend(title = "Reporting Group")) +
  facet_grid(. ~ THA)

THA_2018_5RG_estimates.tdy %>% 
  mutate(value = value * 100) %>% 
  spread(estimator, value) %>% 
  filter(THA == "Neets") %>% 
  ggplot(aes(x = SW_range, y = mean, group = group, fill = group)) +
  geom_col(width = 0.7, position = position_dodge(0.8)) +
  geom_errorbar(aes(ymin = `5%`, ymax = `95%`), width = 0.4, position = position_dodge(0.8)) +
  ylim(c(0, 100)) +
  ylab("Stock Composition (%)") +
  xlab("Stat Week Range") +
  guides(fill = guide_legend(title = "Reporting Group")) +
  facet_grid(. ~ THA)
```


# Spring troll: import mixture genotypes

Read in genotypes from *LOKI* as `.gcl` objects. Save in directory.
```{r spring_loki}
# origins_sillys <- c("KTROL17EW", "KTROL18LW", "KTROL18SP", "KTROL18SU", "KSPORT18", "KTROL18THA", "KGILL18THA", "KSEIN18THA")
spring_2018_sillys <- c("KTROL18SP")
LOKI2R_GAPS.GCL(sillyvec = spring_2018_sillys, username = .username, password = .password)
rm(.username, .password)

sapply(spring_2018_sillys, function(silly) {get(paste0(silly, ".gcl"))$n} )

save_sillys(sillyvec = spring_2018_sillys, path = "../Genotypes/original")
save_objects(objects = c("spring_2018_sillys"), path = "../Objects/")
```

# Join ASL

## Spring Troll

Read in the troll ASL data.
```{r spring_asl, message=FALSE}
(spring_ASL <- read_csv(file = "../ASL Data/2018 Spring Troll Chinook ASLDist Subdistrict.csv") %>% 
   select(`Sample Date`, `Stat Week`, `Port Code`, `Gear`, `Quadrant`, `District`, `Sub/District`, `Dna Specimen No`, `Cwt Strap Tag No`))

# Any duplicate Dna Specimen No?
table(table(spring_ASL$`Dna Specimen No`, useNA = "always"), useNA = "always")
```

Shit, it looks like we have some duplicate Dna Specimen No (1 to be precise). Resolved.
```{r spring_asl_duplicates}
asl_duplicates <- spring_ASL %>% 
  group_by(`Dna Specimen No`) %>% 
  summarise(n = n()) %>% 
  filter(n > 1) %>% 
  pull(`Dna Specimen No`)

spring_ASL %>% 
  filter(`Dna Specimen No` %in% asl_duplicates) %>% 
  arrange(`Dna Specimen No`)
```

Are any of these fish in our spring troll samples?
```{r asl_duplicates_spring_troll}
spring_samples <- KTROL18SP.gcl$attributes %>% 
  mutate(`Dna Specimen No` = as.integer(paste0(str_sub(DNA_TRAY_CODE, 7, 10), str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")))) %>% 
  pull(`Dna Specimen No`)

any(spring_samples %in% asl_duplicates)
```

Yes, this sample is in there twice, they are clearly different fish. One has scale card number 4, the other has 8, I will change the fish with scale card 8 to 587408 in the .csv file.

Cool, none of our ASL duplicate Dna Specimen No are in there. Now verify that all spring samples are in the ASL data.
```{r spring_in_asl}
all(spring_samples %in% spring_ASL$`Dna Specimen No`)
```

Excellent, all samples accounted for!!!

Need to fix Month so it doesn't rely solely on Sample Date, (some fish sampled on June 1 were harvested in May).
```{r spring_asl_statarea}
spring_ASL <- spring_ASL %>% 
  mutate(Subdistrict = str_pad(string = `Sub/District`, width = 2, side = "left", pad = 0)) %>% 
  unite(`Stat Area`, c("District", "Subdistrict"), sep = "", remove = FALSE) %>% 
  mutate(`Sample Date` = mdy(`Sample Date`)) %>% 
  mutate(Month = month(`Sample Date`, label = TRUE, abbr = FALSE))
```

Now that we've resolved our ASL discrepancy, join with attributes to get stat area level information.
```{r join_spring_asl}
# Join ASL with attributes table
# Spring
KTROL18SP.gcl$attributes <- KTROL18SP.gcl$attributes %>% 
  mutate(`Dna Specimen No` = as.integer(paste0(str_sub(DNA_TRAY_CODE, 7, 10), str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")))) %>% 
  left_join(spring_ASL, by = "Dna Specimen No")
```

How many fish per stat area and month??
```{r spring_stat_area_counts}
KTROL18SP.gcl$attributes %>% 
  count(`Stat Area`, Month) %>% 
  spread(Month, n, fill = 0)
```

Whoops, some fish from 113-41 were sampled in "June", but harvested in "May". This is an artifact of when the fishery closed and opened back up (113-41 closed on 5/31, and re-opened on 6/4).
```{r spring_11341_june}
KTROL18SP.gcl$attributes <- KTROL18SP.gcl$attributes %>% 
  mutate(Month = case_when(`Stat Area` == "11341" & `Sample Date` == as_date("2018-06-01") ~ 
                             month(as_date("2018-05-31"), label = TRUE, abbr = FALSE),
                            TRUE ~ Month))

KTROL18SP.gcl$attributes %>% 
  count(`Stat Area`, Month) %>% 
  spread(Month, n, fill = 0)
```


# Define mixture strata

Spring mixtures are each stat area and month by itself (except 113-30 and 183-10, which are combined for May and June). Use `case_when` to creat an attribute in the attributes table for mixture.
```{r spring_mixture_attribute}
KTROL18SP.gcl$attributes <- KTROL18SP.gcl$attributes %>% 
  mutate(mixname = case_when(`Stat Area` == "10145" & Month == "May" ~ "SpringRet1_10145_2018",
                             `Stat Area` == "10145" & Month == "June" ~ "SpringRet2_10145_2018",
                             `Stat Area` == "10350" & Month == "May" ~ "SpringRet1_10350_2018",
                             `Stat Area` == "10350" & Month == "June" ~ "SpringRet2_10350_2018",
                             `Stat Area` == "11301" & Month == "June" ~ "SpringRet2_11301_2018",
                             `Stat Area` == "11330" ~ "Spring_11330_2018",
                             `Stat Area` == "11341" & Month == "May" ~ "SpringRet1_11341_2018",
                             `Stat Area` == "11341" & Month == "June" ~ "SpringRet2_11341_2018",
                             `Stat Area` == "11362" & Month == "June" ~ "SpringRet2_11362_2018",
                             `Stat Area` == "18310" ~ "Spring_18310_2018",
                             TRUE ~ as.character(NA)))

KTROL18SP.gcl$attributes %>% 
  count(mixname)
```

Create spring mixtures.
```{r spring_define_mixtures}
spring_2018_mixnames <- sort(unique(KTROL18SP.gcl$attributes$mixname))

sapply(spring_2018_mixnames, function(mixname) {
  ids <- setNames(object = list(AttributesToIDs.GCL(silly = "KTROL18SP", attribute = "mixname", matching = mixname)), nm = "KTROL18SP")
  PoolCollections.GCL(collections = "KTROL18SP", loci = GAPSLoci_reordered, IDs = ids, newname = mixname)
})

sapply(spring_2018_mixnames, function(silly) {get(paste0(silly, ".gcl"))$n} )
```

Save genotypes for spring strata.
```{r save_spring_strata_genotypes}
if(!dir.exists("../Genotypes/strata")) {dir.create("../Genotypes/strata")}

save_objects(objects = "spring_2018_mixnames", path = "../Objects/")
save_sillys(sillyvec = spring_2018_mixnames, path = "../Genotypes/strata/")
```

# Data QA

Standard data QA:

  * Remove fish missing <80% genotypes
  * Remove duplicates (>95% genotype concordance)

```{r spring_QA}
# original sample sizes
spring_2018_sample_sizes <- tibble(silly = spring_2018_mixnames,
                                   genotyped = sapply(spring_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# missing
spring_2018_missing <- RemoveIndMissLoci.GCL(sillyvec = spring_2018_mixnames, proportion = 0.8)
save_objects("spring_2018_missing", "../Objects/")

spring_2018_sample_sizes <- spring_2018_sample_sizes %>% 
  mutate(missing = genotyped - sapply(spring_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# duplicate
spring_2018_duplicates <- CheckDupWithinSilly.GCL(sillyvec = spring_2018_mixnames, loci = GAPSLoci_reordered, quantile = NULL, minproportion = 0.95)
(spring_2018_duplicates_summary <- sapply(spring_2018_mixnames, function(x) {spring_2018_duplicates[[x]]$report}))
save_objects("spring_2018_duplicates_summary", "../Objects/")

spring_2018_duplciates_removed <- RemoveDups.GCL(dupcheck = spring_2018_duplicates)

spring_2018_sample_sizes <- spring_2018_sample_sizes %>% 
  mutate(duplicate = genotyped - missing - sapply(spring_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# final
spring_2018_sample_sizes <- spring_2018_sample_sizes %>% 
  mutate(final = sapply(spring_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))
spring_2018_sample_sizes
save_objects("spring_2018_sample_sizes", "../Objects/")

write_csv(spring_2018_sample_sizes, "../Tables/spring_2018_sample_sizes.csv")
```

Save post-QA genotypes
```{r spring_post_QA}
if(!dir.exists("../Genotypes/strata_postQA/")) {dir.create("../Genotypes/strata_postQA/")}
save_sillys(sillyvec = spring_2018_mixnames, path = "../Genotypes/strata_postQA")
```

# Create *BAYES* files

## Directory setup

First need to set up *BAYES* directory structure and copy over baseline file and *BAYES* objects. This was already done when we ran TBR.

## Create mixtures

Save the fortran format and create TBR *BAYES* mixture files. This was already done when we ran TBR.
```{r spring_BAYES_mixtures}
# mixfortran <- CreateMixture.GCL(sillys = TBR_sillys[1], loci = GAPSLoci_reordered, IDs = NULL, mixname = TBR_mixnames[TBR_sillys[1]], dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
# save_objects("mixfortran", "../Objects/")

sapply(spring_2018_mixnames, function(mix) {
  CreateMixture.GCL(sillys = mix, loci = GAPSLoci_reordered, IDs = NULL, mixname = mix, dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
} )
```

## Create priors

New this year, I will be analyzing **ALL** Chinook mixtures with the full 33 reporting groups. However, since I ran last year's troll mixtures for just the 26 reporting groups, I will have to mess with the priors a bit. Also a new wrinkle because are running by stat area this year (some are just May - Ret1, some are just June - Ret2, and some are both). Use stratified spring NO for 183-10 and 113-30, otherwise use previous years Ret1 or Ret2 by quad for the quad corresponding to the correct stat area.
```{r spring_read_2017_estimates}
SpringRet1_2017_26RG_EstimatesStats <- dget("../../SEAK17/Estimates objects/SpringRet1_2017_26RG_EstimatesStats.txt")
SpringRet2_2017_26RG_EstimatesStats <- dget("../../SEAK17/Estimates objects/SpringRet2_2017_26RG_EstimatesStats.txt")
SpringNO_2017_26RG_EstimatesStats <- list("SpringNO_2017" = dget("../../SEAK17/Estimates objects/SpringNO_2017_26RG_StratifiedEstimatesStats.txt"))

spring_2017_means <- sapply(c(SpringRet1_2017_26RG_EstimatesStats, 
                               SpringRet2_2017_26RG_EstimatesStats, 
                               SpringNO_2017_26RG_EstimatesStats), function(mix) {
  mix[, "mean"]
} )

dimnames(spring_2017_means)
```

My plan is to keep the same prior for the 26 groups and then spread out the prior evenly across all other 33 reporting groups.
```{r spring_setup_2018_priors}
# Convert from 26RG to 33RG
spring_2017_means_33RG <- apply(spring_2017_means, 2, function(mix) {mix[GroupVec33RG_to26RG] / table(GroupVec33RG_to26RG)[GroupVec33RG_to26RG]} )
rownames(spring_2017_means_33RG) <- GroupNames33

# Duplicate NISISO to NI, SI, SO
spring_2017_means_33RG <- spring_2017_means_33RG[, c(9, 9, 3, 4, 2, 7, 8, 6, 6, 6)]

# Fix dimnames
colnames(spring_2017_means_33RG) <- spring_2018_mixnames

# Verify
apply(spring_2017_means_33RG, 2, sum)
```

Now create 2018 priors.
```{r spring_create_2018_priors}
spring_2018_priors <- apply(spring_2017_means_33RG, 2, function(mix) {
  Prior.GCL(groupvec = GroupVec33RG_357, groupweights = mix, minval = 0.01)
} )
colnames(spring_2018_priors) <- spring_2018_mixnames
save_objects("spring_2018_priors", "../Objects/")
```

## Create control files

Now that we have priors, just need to create *BAYES* control files.
```{r spring_BAYES_control}
sapply(spring_2018_mixnames, function(mix) {
  CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = mix, basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                        nchains = 5, groupvec = GroupVec33RG_357, priorvec = spring_2018_priors[, mix], initmat = GAPS357PopsInits, 
                        dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                        basefortran = bayesfortran_357, switches = "F T F T T T F")
} )
```

## Create output directories

```{r spring_BAYES_output}
sapply(spring_2018_mixnames, function(mix) {dir.create(paste0("../BAYES/Output/", mix))} )
```

# Summarize *BAYES* results

Summarize results for both the full 33 reporting groups, the 5 TBR groups, 3 TBR groups, and 2 TBR groups.

## 33 reporting groups

Create standard summary and save.
```{r spring_BAYES_summarise_33RG}
# full 33 reporting groups
Spring_2018_33RG_EstimatesStats <- 
  CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, maindir = "../BAYES/Output", mixvec = spring_2018_mixnames,
                               prior = "", ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1, PosteriorOutput = FALSE)

# dir.create("../Estimates objects")
save_objects(c("Spring_2018_33RG_EstimatesStats"), "../Estimates objects")
```

Make in to tall tibble.
```{r spring_BAYES_33RG_tibble}
# make in to a tidy tibble (tall)
spring_2018_33RG_estimates.tdy <- 
  bind_rows(
    lapply(spring_2018_mixnames, function(mix) {  # loop over mixture names
      c(Spring_2018_33RG_EstimatesStats)[[mix]] %>%  # for each matrix
        as_tibble(rownames = "group") %>%  # make tibble with rownames as group
        mutate(mixname = mix) %>%  # make column for mixname
        mutate(n_group = n_distinct(group))  # make column for number of groups
    } )
  ) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("period", "stat_area", "year"), sep = "_", remove = FALSE) %>%  # extract mixture and year
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames33))  # factor for ordering

save_objects(c("spring_2018_33RG_estimates.tdy"), "../Estimates objects")
```

Check GR
```{r spring_GR}
spring_2018_33RG_estimates.tdy %>% 
  filter(estimator == "GR") %>% 
  filter(value > 1.2)
```

This is why we report to Interior Columbia Su/Fa, not to summer and fall separately.

## 5 reporting groups

Create standard summary and tall tibble, save both.
```{r BAYES_summarise_spring_5RG}
Spring_2018_5RG_EstimatesStats <- 
  CustomCombineBAYESOutput.GCL(groupvec = GroupVec5RG_THA_33, groupnames = GroupNames5_THA, maindir = "../BAYES/Output", 
                               mixvec = spring_2018_mixnames,
                               prior = "", ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1, PosteriorOutput = FALSE)

# make in to a tidy tibble (tall)
spring_2018_5RG_estimates.tdy <- 
  bind_rows(
    lapply(spring_2018_mixnames, function(mix) {  # loop over mixture names
      c(Spring_2018_5RG_EstimatesStats)[[mix]] %>%  # for each matrix
        as_tibble(rownames = "group") %>%  # make tibble with rownames as group
        mutate(mixname = mix) %>%  # make column for mixname
        mutate(n_group = n_distinct(group))  # make column for number of groups
    } )
  ) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("period", "stat_area", "year"), sep = "_", remove = FALSE) %>%  # extract mixture and year
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames5_THA))  # factor for ordering

save_objects(c("Spring_2018_5RG_EstimatesStats", "spring_2018_5RG_estimates.tdy"), "../Estimates objects")
```

# Harvest - Spring troll

Read in harvest data

```{r spring_harvest}
(spring_harvest <- read_csv("../Harvest Data/ft - Detailed Fish Tickets_spring.csv") %>% 
  mutate(Month = month(`Date Fishing Ended`, label = TRUE, abbr = FALSE)) %>% 
  group_by(District, `Stat Area`, Month) %>% 
  summarise(Harvest = sum(`Number Of Animals (sum)`, na.rm = TRUE)))
```

```{r spring_troll_figures, out.width="100%"}
spring_2018_33RG_estimates.tdy %>% 
  spread(estimator, value) %>% 
  filter(mean > 0.05) %>% 
  arrange(mixname, desc(mean))

spring_2018_33RG_estimates.tdy %>% 
  spread(estimator, value) %>% 
  filter(stat_area == "10145") %>% 
  mutate(month = case_when(period == "SpringRet1" ~ "May",
                           period == "SpringRet2" ~ "June", 
                           period == "Spring" ~ "Spring")) %>% 
  mutate(month = factor(x = month, levels = month.name)) %>% 
  ggplot(aes(x = group, y = mean * 100)) +
  geom_col(fill = "lightblue") +
  geom_errorbar(aes(ymin = `5%` * 100, ymax = `95%` * 100)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  ylab("Stock Composition (%)") +
  xlab("Reporting Group") +
  ggtitle("Spring Troll AY 2018: Mountain Point 101-45") +
  facet_grid(. ~ month)


```

# Summer troll: import mixture genotypes

Read in genotypes from *LOKI* as `.gcl` objects. Save in directory.
```{r summer_loki}
# origins_sillys <- c("KTROL17EW", "KTROL18LW", "KTROL18SP", "KTROL18SU", "KSPORT18", "KTROL18THA", "KGILL18THA", "KSEIN18THA")
summer_2018_sillys <- c("KTROL18SU")
LOKI2R_GAPS.GCL(sillyvec = summer_2018_sillys, username = .username, password = .password)
rm(.username, .password)

sapply(summer_2018_sillys, function(silly) {get(paste0(silly, ".gcl"))$n} )

save_sillys(sillyvec = summer_2018_sillys, path = "../Genotypes/original")
save_objects(objects = c("summer_2018_sillys"), path = "../Objects/")
```

# Join ASL

## Summer Troll

Read in the troll ASL data.
```{r summer_asl, message=FALSE}
(summer_ASL <- read_csv(file = "../ASL Data/2018 Summer Troll Chinook with Dist Sub Dist.csv") %>% 
   select(`Sample Date`, `Stat Week`, `Port Code`, `Gear`, `Quadrant`, `District`, `Sub/District`, `Dna Specimen No`, `Cwt Strap Tag No`))

# Any duplicate Dna Specimen No?
table(table(summer_ASL$`Dna Specimen No`, useNA = "always"), useNA = "always")
```

No duplicates, great. Get the Dna Specimen No for the fish we ran and verify that all summer samples are in the ASL data.
```{r summer_in_asl}
summer_samples <- KTROL18SU.gcl$attributes %>% 
  mutate(`Dna Specimen No` = as.integer(paste0(str_sub(DNA_TRAY_CODE, 7, 10), str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")))) %>% 
  pull(`Dna Specimen No`)

all(summer_samples %in% summer_ASL$`Dna Specimen No`)
```

Excellent, all samples accounted for!!!

Make date and get month. District and sub-district are complicated, so we are going to ignore for now.
```{r summer_asl_statarea}
summer_ASL <- summer_ASL %>% 
  # mutate(Subdistrict = str_pad(string = `Sub/District`, width = 2, side = "left", pad = 0)) %>% 
  # unite(`Stat Area`, c("District", "Subdistrict"), sep = "", remove = FALSE) %>% 
  mutate(`Sample Date` = mdy(`Sample Date`)) %>% 
  mutate(Month = month(`Sample Date`, label = TRUE, abbr = FALSE))
```

Join with attributes to get stat area level information.
```{r join_summer_asl}
# Join ASL with attributes table
# Summer
KTROL18SU.gcl$attributes <- KTROL18SU.gcl$attributes %>% 
  mutate(`Dna Specimen No` = as.integer(paste0(str_sub(DNA_TRAY_CODE, 7, 10), str_pad(DNA_TRAY_WELL_CODE, 2, "left", "0")))) %>% 
  left_join(summer_ASL, by = "Dna Specimen No")
```

How many fish per Quadrant and retention period (month)?
```{r summer_stat_area_counts}
KTROL18SU.gcl$attributes %>% 
  count(Quadrant, Month) %>% 
  spread(Month, n, fill = 0)
```

Looks good! Lost some fish in the genotyping process, but not too many.

# Define mixture strata

Summer mixtures are each stat area and month by itself (except 113-30 and 183-10, which are combined for May and June). Use `case_when` to creat an attribute in the attributes table for mixture.
```{r summer_mixture_attribute}
KTROL18SU.gcl$attributes <- KTROL18SU.gcl$attributes %>% 
  mutate(mixname = case_when(Quadrant == 171 & Month == "July" ~ "SummerRet1NO_2018",
                             Quadrant == 172 & Month == "July" ~ "SummerRet1SO_2018",
                             Quadrant == 173 & Month == "July" ~ "SummerRet1NI_2018",
                             Quadrant == 174 & Month == "July" ~ "SummerRet1SI_2018",
                             Quadrant == 171 & Month == "August" ~ "SummerRet2NO_2018",
                             Quadrant == 172 & Month == "August" ~ "SummerRet2SO_2018",
                             Quadrant == 173 & Month == "August" ~ "SummerRet2NI_2018",
                             Quadrant == 174 & Month == "August" ~ "SummerRet2SI_2018",
                             TRUE ~ as.character(NA)))

KTROL18SU.gcl$attributes %>% 
  count(mixname)
```

Create summer mixtures.
```{r summer_define_mixtures}
summer_2018_mixnames <- sort(unique(KTROL18SU.gcl$attributes$mixname))

sapply(summer_2018_mixnames, function(mixname) {
  ids <- setNames(object = list(AttributesToIDs.GCL(silly = "KTROL18SU", attribute = "mixname", matching = mixname)), nm = "KTROL18SU")
  PoolCollections.GCL(collections = "KTROL18SU", loci = GAPSLoci_reordered, IDs = ids, newname = mixname)
})

sapply(summer_2018_mixnames, function(silly) {get(paste0(silly, ".gcl"))$n} )
```

Save genotypes for summer strata.
```{r save_summer_strata_genotypes}
if(!dir.exists("../Genotypes/strata")) {dir.create("../Genotypes/strata")}

save_objects(objects = "summer_2018_mixnames", path = "../Objects/")
save_sillys(sillyvec = summer_2018_mixnames, path = "../Genotypes/strata/")
```

# Data QA

Standard data QA:

  * Remove fish missing <80% genotypes
  * Remove duplicates (>95% genotype concordance)

```{r summer_QA}
# original sample sizes
summer_2018_sample_sizes <- tibble(silly = summer_2018_mixnames,
                                   genotyped = sapply(summer_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# missing
summer_2018_missing <- RemoveIndMissLoci.GCL(sillyvec = summer_2018_mixnames, proportion = 0.8)
save_objects("summer_2018_missing", "../Objects/")

summer_2018_sample_sizes <- summer_2018_sample_sizes %>% 
  mutate(missing = genotyped - sapply(summer_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# duplicate
summer_2018_duplicates <- CheckDupWithinSilly.GCL(sillyvec = summer_2018_mixnames, loci = GAPSLoci_reordered, quantile = NULL, minproportion = 0.95)
(summer_2018_duplicates_summary <- sapply(summer_2018_mixnames, function(x) {summer_2018_duplicates[[x]]$report}))
save_objects("summer_2018_duplicates_summary", "../Objects/")

summer_2018_duplciates_removed <- RemoveDups.GCL(dupcheck = summer_2018_duplicates)

summer_2018_sample_sizes <- summer_2018_sample_sizes %>% 
  mutate(duplicate = genotyped - missing - sapply(summer_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# final
summer_2018_sample_sizes <- summer_2018_sample_sizes %>% 
  mutate(final = sapply(summer_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))
summer_2018_sample_sizes
save_objects("summer_2018_sample_sizes", "../Objects/")

write_csv(summer_2018_sample_sizes, "../Tables/summer_2018_sample_sizes.csv")
```

Save post-QA genotypes
```{r summer_post_QA}
if(!dir.exists("../Genotypes/strata_postQA/")) {dir.create("../Genotypes/strata_postQA/")}
save_sillys(sillyvec = summer_2018_mixnames, path = "../Genotypes/strata_postQA")
```

# Create *BAYES* files

## Directory setup

First need to set up *BAYES* directory structure and copy over baseline file and *BAYES* objects. This was already done when we ran TBR.

## Create mixtures

Save the fortran format and create TBR *BAYES* mixture files. This was already done when we ran TBR.
```{r summer_BAYES_mixtures}
# mixfortran <- CreateMixture.GCL(sillys = TBR_sillys[1], loci = GAPSLoci_reordered, IDs = NULL, mixname = TBR_mixnames[TBR_sillys[1]], dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
# save_objects("mixfortran", "../Objects/")

sapply(summer_2018_mixnames, function(mix) {
  CreateMixture.GCL(sillys = mix, loci = GAPSLoci_reordered, IDs = NULL, mixname = mix, dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
} )
```

## Create priors

New this year, I will be analyzing **ALL** Chinook mixtures with the full 33 reporting groups. However, since I ran last year's troll mixtures for just the 26 reporting groups, I will have to mess with the priors a bit. 

Also since there was no 2nd retention opener in 2017, we'll use 2018 Retention 1 as a prior.
```{r summer_read_2017_estimates}
SummerRet1_2017_26RG_EstimatesStats <- dget("../../SEAK17/Estimates objects/SummerRet1_2017_26RG_EstimatesStats.txt")

summer_2017_means <- sapply(c(SummerRet1_2017_26RG_EstimatesStats), function(mix) {
  mix[, "mean"]
} )

dimnames(summer_2017_means)
```

My plan is to keep the same prior for the 26 groups and then spread out the prior evenly across all other 33 reporting groups.
```{r summer_setup_2018_priors}
# Convert from 26RG to 33RG
summer_ret1_2017_means_33RG <- apply(summer_2017_means, 2, function(mix) {mix[GroupVec33RG_to26RG] / table(GroupVec33RG_to26RG)[GroupVec33RG_to26RG]} )
rownames(summer_ret1_2017_means_33RG) <- GroupNames33

# Fix dimnames
colnames(summer_ret1_2017_means_33RG) <- summer_2018_mixnames[1:4]

# Verify
apply(summer_ret1_2017_means_33RG, 2, sum)
```

Now create 2018 priors.
```{r summer_create_2018_priors}
summer_ret1_2018_priors <- apply(summer_ret1_2017_means_33RG, 2, function(mix) {
  Prior.GCL(groupvec = GroupVec33RG_357, groupweights = mix, minval = 0.01)
} )
colnames(summer_ret1_2018_priors) <- summer_2018_mixnames[1:4]
save_objects("summer_ret1_2018_priors", "../Objects/")
```

## Create control files

Now that we have priors, just need to create *BAYES* control files.
```{r summer_BAYES_control}
sapply(summer_2018_mixnames[1:4], function(mix) {
  CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = mix, basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                        nchains = 5, groupvec = GroupVec33RG_357, priorvec = summer_ret1_2018_priors[, mix], initmat = GAPS357PopsInits, 
                        dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                        basefortran = bayesfortran_357, switches = "F T F T T T F")
} )
```

## Create output directories

```{r summer_BAYES_output}
sapply(summer_2018_mixnames[1:4], function(mix) {dir.create(paste0("../BAYES/Output/", mix))} )
```

# Summarize *BAYES* results

Summarize results for both the full 33 reporting groups, the 5 TBR groups, 3 TBR groups, and 2 TBR groups.

## 33 reporting groups

Create standard summary and save.
```{r summer_ret1_BAYES_summarise_33RG}
# full 33 reporting groups
SummerRet1_2018_33RG_EstimatesStats <- 
  CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, maindir = "../BAYES/Output", mixvec = summer_2018_mixnames[1:4],
                               prior = "", ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1, PosteriorOutput = FALSE)

# dir.create("../Estimates objects")
save_objects(c("SummerRet1_2018_33RG_EstimatesStats"), "../Estimates objects")
```

Check Gelman-Rubin
```{r summer_ret1_GR_33RG}
any(sapply(SummerRet1_2018_33RG_EstimatesStats, function(mix) {mix[, "GR"]} ) > 1.2)
sum(sapply(SummerRet1_2018_33RG_EstimatesStats, function(mix) {mix[, "GR"]} ) > 1.2)
sapply(SummerRet1_2018_33RG_EstimatesStats, function(mix) {mix[, "GR"]} )
```

Just Alsek in NO quadrant, estimate is super low, so no big deal.
```{r}
SummerRet1_2018_33RG_EstimatesStats[["SummerRet1NO_2018"]]["Alsek", ]
```

# Create *BAYES* files

## Create priors for Ret2

New this year, I will be analyzing **ALL** Chinook mixtures with the full 33 reporting groups. However, since I ran last year's troll mixtures for just the 26 reporting groups, I will have to mess with the priors a bit. 

Use 2018 Retention 1 as a prior for Retention 2.
```{r summer_ret1_read_2018_estimates}
summer_ret1_2018_means_33RG <- sapply(c(SummerRet1_2018_33RG_EstimatesStats), function(mix) {
  mix[, "mean"]
} )

dimnames(summer_ret1_2018_means_33RG)
```

My plan is to keep the same prior for the 26 groups and then spread out the prior evenly across all other 33 reporting groups.
```{r summer_ret2_setup_2018_priors}
# Fix dimnames
colnames(summer_ret1_2018_means_33RG) <- summer_2018_mixnames[5:8]

# Verify
apply(summer_ret1_2018_means_33RG, 2, sum)
```

Now create 2018 priors.
```{r summer_ret2_create_2018_priors}
summer_ret2_2018_priors <- apply(summer_ret1_2018_means_33RG, 2, function(mix) {
  Prior.GCL(groupvec = GroupVec33RG_357, groupweights = mix, minval = 0.01)
} )
colnames(summer_ret2_2018_priors) <- summer_2018_mixnames[5:8]
save_objects("summer_ret2_2018_priors", "../Objects/")
```

## Create control files

Now that we have priors, just need to create *BAYES* control files.
```{r summer_ret2_BAYES_control}
sapply(summer_2018_mixnames[5:8], function(mix) {
  CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = mix, basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                        nchains = 5, groupvec = GroupVec33RG_357, priorvec = summer_ret2_2018_priors[, mix], initmat = GAPS357PopsInits, 
                        dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                        basefortran = bayesfortran_357, switches = "F T F T T T F")
} )
```

## Create output directories

```{r summer_ret2_BAYES_output}
sapply(summer_2018_mixnames[5:8], function(mix) {dir.create(paste0("../BAYES/Output/", mix))} )
```

# Summarize *BAYES* results

Summarize results for both the full 33 reporting groups, the 5 TBR groups, 3 TBR groups, and 2 TBR groups.

## 33 reporting groups

Create standard summary and save.
```{r summer_ret2_BAYES_summarise_33RG}
# full 33 reporting groups
SummerRet2_2018_33RG_EstimatesStats <- 
  CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, maindir = "../BAYES/Output", mixvec = summer_2018_mixnames[5:8],
                               prior = "", ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1, PosteriorOutput = FALSE)

# dir.create("../Estimates objects")
save_objects(c("SummerRet2_2018_33RG_EstimatesStats"), "../Estimates objects")
```

Check Gelman-Rubin
```{r summer_ret2_GR_33RG}
any(sapply(SummerRet2_2018_33RG_EstimatesStats, function(mix) {mix[, "GR"]} ) > 1.2)
sum(sapply(SummerRet2_2018_33RG_EstimatesStats, function(mix) {mix[, "GR"]} ) > 1.2)
sapply(SummerRet2_2018_33RG_EstimatesStats, function(mix) {mix[, "GR"]} )
```

Just NThompson, WCascadeSp, and LoColFa in SO quadrant, estimate is super low (other than LoColFa), so not a huge deal.
```{r}
SummerRet2_2018_33RG_EstimatesStats[["SummerRet2SO_2018"]][c("NThompson", "WCascadeSp", "LoColFa"), ]
```

## 33 reporting groups

Create standard summary and save for all Summer (Ret1 + Ret2).
```{r summer_BAYES_summarise_33RG}
# full 33 reporting groups
Summer_2018_33RG_EstimatesStats <- 
  CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, maindir = "../BAYES/Output", mixvec = summer_2018_mixnames,
                               prior = "", ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1, PosteriorOutput = FALSE)

# dir.create("../Estimates objects")
save_objects(c("Summer_2018_33RG_EstimatesStats"), "../Estimates objects")
```

Make in to tall tibble.
```{r summer_BAYES_33RG_tibble}
# make in to a tidy tibble (tall)
summer_2018_33RG_estimates.tdy <- 
  bind_rows(
    lapply(summer_2018_mixnames, function(mix) {  # loop over mixture names
      c(Summer_2018_33RG_EstimatesStats)[[mix]] %>%  # for each matrix
        as_tibble(rownames = "group") %>%  # make tibble with rownames as group
        mutate(mixname = mix) %>%  # make column for mixname
        mutate(n_group = n_distinct(group))  # make column for number of groups
    } )
  ) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("mix", "year"), sep = "_", remove = FALSE) %>%  # extract mixture and year
  separate(mix, c("fishery", "quadrant"), sep = 10) %>%  # extract district and gear
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames33))  # factor for ordering

save_objects(c("summer_2018_33RG_estimates.tdy"), "../Estimates objects")
```

Check GR
```{r summer_GR}
summer_2018_33RG_estimates.tdy %>% 
  filter(estimator == "GR") %>% 
  filter(value > 1.2)
```

## 5 reporting groups

Create standard summary and tall tibble, save both.
```{r BAYES_summarise_summer_5RG}
Summer_2018_5RG_EstimatesStats <- 
  CustomCombineBAYESOutput.GCL(groupvec = GroupVec5RG_THA_33, groupnames = GroupNames5_THA, maindir = "../BAYES/Output", 
                               mixvec = summer_2018_mixnames,
                               prior = "", ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1, PosteriorOutput = FALSE)

# make in to a tidy tibble (tall)
summer_2018_5RG_estimates.tdy <- 
  bind_rows(
    lapply(summer_2018_mixnames, function(mix) {  # loop over mixture names
      c(Summer_2018_5RG_EstimatesStats)[[mix]] %>%  # for each matrix
        as_tibble(rownames = "group") %>%  # make tibble with rownames as group
        mutate(mixname = mix) %>%  # make column for mixname
        mutate(n_group = n_distinct(group))  # make column for number of groups
    } )
  ) %>% 
  gather(estimator, value, -mixname, -group, - n_group) %>%  # gather all estimators
  separate(mixname, c("mix", "year"), sep = "_", remove = FALSE) %>%  # extract mixture and year
  separate(mix, c("fishery", "quadrant"), sep = 10) %>%  # extract district and gear
  mutate(estimator = factor(estimator, c("mean", "sd", "5%", "95%", "median", "P=0", "GR"))) %>%  # factor for ordering
  mutate(group = factor(group, GroupNames5_THA))  # factor for ordering

save_objects(c("Summer_2018_5RG_EstimatesStats", "summer_2018_5RG_estimates.tdy"), "../Estimates objects")
```

# Sport troll: import mixture genotypes

Read in genotypes from *LOKI* as `.gcl` objects. Save in directory.
```{r sport_loki}
# origins_sillys <- c("KTROL17EW", "KTROL18LW", "KTROL18SP", "KTROL18SU", "KSPORT18", "KTROL18THA", "KGILL18THA", "KSEIN18THA")
sport_2018_sillys <- c("KSPORT18")
LOKI2R_GAPS.GCL(sillyvec = sport_2018_sillys, username = .username, password = .password)
rm(.username, .password)

sapply(sport_2018_sillys, function(silly) {get(paste0(silly, ".gcl"))$n} )

save_sillys(sillyvec = sport_2018_sillys, path = "../Genotypes/original")
save_objects(objects = c("sport_2018_sillys"), path = "../Objects/")
```

# Join ASL

## Sport Troll

Read in the troll ASL data.
```{r sport_asl, message=FALSE}
(sport_ASL <- read_csv(file = "../ASL Data/_2018_SEAK_SF_Whatman_AWL_10OCT18.csv") %>% 
   select(Year, SITE, DATE, BIWEEK, STATWEEK, SPECCODE, LENGTH, Whatman_Card, SAMPLE_NO, Adipose_Clipped, DISTRICT, STAT_AREA, Stat_Area_label) %>% 
   mutate(WGC = str_pad(Whatman_Card, 10, "left", "0")) %>% 
   unite(fish_id, c("WGC", "SAMPLE_NO"), sep = "_", remove = FALSE) %>% 
   filter(SPECCODE == 410) %>%
   filter(!is.na(SAMPLE_NO)) %>%
   mutate(site = factor(SITE, c("JUNEAU", "KETCHIKAN", "WRANGELL", "PETERSBURG", "SITKA", "CRAIG_KLAWOCK", "GUSTAVUS", "ELFIN_COVE", "YAKUTAT"))) %>% 
   rename(biweek = BIWEEK) %>% 
   mutate(fishery = case_when(site == "KETCHIKAN" ~ "KTN",
                              site %in% c("PETERSBURG", "WRANGELL") ~ "PB-WR",
                              site == "JUNEAU" ~ "Inside",
                              site %in% c("YAKUTAT", "GUSTAVUS", "ELFIN_COVE", "SITKA", "CRAIG_KLAWOCK") & biweek <= 13 ~ "Outside_early",
                              site %in% c("YAKUTAT", "GUSTAVUS", "ELFIN_COVE", "SITKA", "CRAIG_KLAWOCK") & biweek > 13 ~ "Outside_late")) %>% 
   mutate(fishery = factor(fishery, levels = c("KTN", "PB-WR", "Inside", "Outside_early", "Outside_late")))
)

# Any duplicate Dna Specimen No?
table(table(sport_ASL$fish_id, useNA = "always"), useNA = "always")
```

No duplicates, great. Get the fish_id for the fish we ran and verify that all sport samples are in the ASL data.
```{r sport_in_asl}
sport_samples <- KSPORT18.gcl$attributes %>% 
  unite(fish_id, c("DNA_TRAY_CODE", "DNA_TRAY_WELL_CODE"), sep = "_", remove = FALSE) %>% 
  pull(fish_id)

all(sport_samples %in% sport_ASL$fish_id)

setdiff(sport_samples, sport_ASL$fish_id)
```

Excellent, all samples accounted for (except for two 411s)!!

Join with attributes to get port and biweek level information.
```{r join_sport_asl}
# Join ASL with attributes table
# Sport
KSPORT18.gcl$attributes <- KSPORT18.gcl$attributes %>% 
  unite(fish_id, c("DNA_TRAY_CODE", "DNA_TRAY_WELL_CODE"), sep = "_", remove = FALSE) %>% 
  left_join(sport_ASL, by = "fish_id")
```

How many fish per Port and Biweek?
```{r sport_stat_area_counts}
KSPORT18.gcl$attributes %>% 
  count(site, biweek) %>% 
  spread(site, n, fill = 0)
```

Looks good! Lost some fish in the genotyping process, but not too many.

# Define mixture strata

## Simple mixtures

Sport mixtures are by port and biweek, some mixtures are overlapping. Use `case_when` to creat an attribute in the attributes table for "simple" mixtures. Verify samples per biweek by cross checking with ExtractionLists.R. **Note** can't have mixname for other = NA, it messes up `AttributesToIDs`.
```{r sport_mixture_attribute}
KSPORT18.gcl$attributes <- KSPORT18.gcl$attributes %>% 
  mutate(mixname = case_when(site == "CRAIG_KLAWOCK" ~ "CRGSport_2018",
                             site == "SITKA" ~ "SITSport_2018",
                             site == "KETCHIKAN" ~ "KTNSport_2018",
                             TRUE ~ "complex_mixture"))

KSPORT18.gcl$attributes %>% 
  count(mixname)
```

We lost some Craig, Ketchikan, and Sitka fish during genotyping, but not enough to redefine the mixtures. These should be good to go.

Create sport mixtures.
```{r sport_define_mixtures}
sport_2018_mixnames <- sort(unique(KSPORT18.gcl$attributes$mixname))[-1]

sapply(sport_2018_mixnames, function(mixname) {
  ids <- setNames(object = list(AttributesToIDs.GCL(silly = "KSPORT18", attribute = "mixname", matching = mixname)), nm = "KSPORT18")
  PoolCollections.GCL(collections = "KSPORT18", loci = GAPSLoci_reordered, IDs = ids, newname = mixname)
})

sapply(sport_2018_mixnames, function(silly) {get(paste0(silly, ".gcl"))$n} )
```

Save genotypes for sport strata.
```{r save_sport_strata_genotypes}
if(!dir.exists("../Genotypes/strata")) {dir.create("../Genotypes/strata")}

# save_objects(objects = "sport_2018_mixnames", path = "../Objects/")
save_sillys(sillyvec = sport_2018_mixnames, path = "../Genotypes/strata/")
```

## Complex mixtures

Need to thin out PBG/WRN + Inside (too many fish run for TBR), also need to thin SIT and CRG for Outside Period 1 and 2.

Get harvest information and join with ASL in order to recreate what was used in ExtractionLists.R

```{r sport_asl_harvest_join}
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Read in ASL data
asl_sport <- read_csv(file = "../ASL Data/_2018_SEAK_SF_Whatman_AWL_10OCT18.csv")

#~~~~~~~~~~~~~~~~~~
## Manipulate ASL data
# Filter for just species 410 (legal), only DNA sampled
asl_sport <- asl_sport %>% 
  filter(SPECCODE == 410) %>% 
  filter(!is.na(SAMPLE_NO))

# Make SITE a factor for ordering purposes
asl_sport <- asl_sport %>% 
  mutate(site = factor(SITE, c("JUNEAU", "KETCHIKAN", "WRANGELL", "PETERSBURG", "SITKA", "CRAIG_KLAWOCK", "GUSTAVUS", "ELFIN_COVE", "YAKUTAT"))) %>% 
  rename(biweek = BIWEEK)

# Create a variable for Fishery
asl_sport <- asl_sport %>% 
  mutate(fishery = case_when(site == "KETCHIKAN" ~ "KTN",
                             site %in% c("PETERSBURG", "WRANGELL") ~ "PB-WR",
                             site == "JUNEAU" ~ "Inside",
                             site %in% c("YAKUTAT", "GUSTAVUS", "ELFIN_COVE", "SITKA", "CRAIG_KLAWOCK") & biweek <= 13 ~ "Outside_early",
                             site %in% c("YAKUTAT", "GUSTAVUS", "ELFIN_COVE", "SITKA", "CRAIG_KLAWOCK") & biweek > 13 ~ "Outside_late")) %>% 
  mutate(fishery = factor(fishery, levels = c("KTN", "PB-WR", "Inside", "Outside_early", "Outside_late")))

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Read in Harvest data
# By Site and Biweek
harvest_sport <- read_csv(file = "../Harvest Data/preliminary_2018_sport_harvest_chinook.csv")

#~~~~~~~~~~~~~~~~~~
## Manipulate harvest data
# Make data tall (tidy), recode sites to ALL CAPS
level_key <- list("Juneau" = "JUNEAU", 
                  "Ketchikan" = "KETCHIKAN", 
                  "Wrangell" = "WRANGELL", 
                  "Petersburg" = "PETERSBURG", 
                  "Sitka" = "SITKA", 
                  "Craig" = "CRAIG_KLAWOCK", 
                  "Gustavus" = "GUSTAVUS", 
                  "Elfin Cove" = "ELFIN_COVE", 
                  "Yakutat" = "YAKUTAT")

harvest_sport <- harvest_sport %>% 
  gather(site, harvest, -biweek) %>% 
  mutate(site = recode_factor(site, !!!level_key, .ordered = TRUE))

# Create a variable for Fishery
harvest_sport <- harvest_sport %>% 
  mutate(fishery = case_when(site == "KETCHIKAN" ~ "KTN",
                             site %in% c("PETERSBURG", "WRANGELL") ~ "PB-WR",
                             site == "JUNEAU" ~ "Inside",
                             site %in% c("YAKUTAT", "GUSTAVUS", "ELFIN_COVE", "SITKA", "CRAIG_KLAWOCK") & biweek <= 13 ~ "Outside_early",
                             site %in% c("YAKUTAT", "GUSTAVUS", "ELFIN_COVE", "SITKA", "CRAIG_KLAWOCK") & biweek > 13 ~ "Outside_late")) %>% 
  mutate(fishery = factor(fishery, levels = c("KTN", "PB-WR", "Inside", "Outside_early", "Outside_late")))

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Join ASL and Harvest data by Site and Biweek
# Roll up ASL to biweek and site level, join with harvest
join_sport <- asl_sport %>% 
  count(site, biweek) %>% 
  full_join(harvest_sport, by = c("site", "biweek")) %>%  # very important to do a full join in case some weeks are missing harvest or samples
  replace_na(list(n = 0, harvest = 0))  # replace NA in samples and harvest with 0
```

### Inside

What was the plan (i.e. ideal mixture sample size per biweek)?
```{r sport_inside_mixture_ideal}
# What does proportional sampling look like?
(extraction_JNU <- join_sport %>% 
   filter(site == "JUNEAU") %>% 
   arrange(biweek) %>% 
   mutate(p_harvest = round(harvest / sum(harvest) * 190)) %>%  # if we want 190 samples proportional to harvest by SW
   mutate(n_sufficeint = n >= p_harvest) %>% 
   mutate(n_remainings = n - p_harvest) %>% 
   mutate(n_extract = pmin(n, p_harvest)) %>% 
   select(site, biweek, n_extract))
```

What do we have (i.e. how many fish per biweek made it through genotypeing)? Make adjustments
```{r sport_inside_mixture_n}
(selection_JNU <- KSPORT18.gcl$attributes %>% 
  filter(site == "JUNEAU") %>% 
  count(site, biweek) %>% 
  right_join(extraction_JNU, by = c("site", "biweek")) %>% 
  replace_na(list(n = 0)) %>% 
  mutate(diff = n - n_extract) %>% 
  mutate(n_select = pmin(n, n_extract)))
```

Pick fish and create mixture.
```{r sport_inside_mixture_create}
ids_inside <- KSPORT18.gcl$attributes %>% 
  filter(site == "JUNEAU") %>% 
  nest(-biweek) %>% 
  right_join(filter(selection_JNU, n_select > 0), by = "biweek") %>% 
  mutate(sample = map2(data, n_select, sample_n)) %>% 
  unnest(sample) %>% 
  mutate(ids = as.character(FK_FISH_ID)) %>% 
  pull(ids)

ids_inside <- list("KSPORT18" = ids_inside)

PoolCollections.GCL(collections = "KSPORT18", loci = GAPSLoci_reordered, IDs = ids_inside, newname = "InsideSport_2018")
```

Verify that we picked fish appropriately.
```{r sport_inside_mixture_verify}
InsideSport_2018.gcl$attributes %>% 
  count(biweek)
```

Save genotypes for sport strata.
```{r save_sport_inside_strata_genotypes}
save_sillys(sillyvec = "InsideSport_2018", path = "../Genotypes/strata/")
```

### PBG/WRN

What was the plan (i.e. ideal mixture sample size per biweek)?
```{r sport_PBGWRN_mixture_ideal}
# What does proportional sampling look like?
(extraction_PBGWRN <- join_sport %>% 
   filter(site %in% c("PETERSBURG", "WRANGELL")) %>% 
   arrange(biweek) %>% 
   mutate(p_harvest = round(harvest / sum(harvest) * 100)) %>%  # if we want 100 samples proportional to harvest by SW
   mutate(n_sufficeint = n >= p_harvest) %>% 
   mutate(n_remainings = n - p_harvest) %>% 
   mutate(n_extract = pmin(n, p_harvest)) %>% 
   select(site, biweek, n_extract))
```

What do we have (i.e. how many fish per biweek made it through genotypeing)? Make adjustments
```{r sport_PBGWRN_mixture_n}
(selection_PBGWRN <- KSPORT18.gcl$attributes %>% 
  filter(site %in% c("PETERSBURG", "WRANGELL")) %>% 
  count(site, biweek) %>% 
  right_join(extraction_PBGWRN, by = c("site", "biweek")) %>% 
  replace_na(list(n = 0)) %>% 
  mutate(diff = n - n_extract) %>% 
  mutate(n_select = pmin(n, n_extract)))
```

Pick fish and create mixture.
```{r sport_PBGWRN_mixture_create}
ids_PBGWRN <- KSPORT18.gcl$attributes %>% 
  filter(site %in% c("PETERSBURG", "WRANGELL")) %>% 
  nest(-site, -biweek) %>% 
  right_join(filter(selection_PBGWRN, n_select > 0), by = c("site", "biweek")) %>% 
  mutate(sample = map2(data, n_select, sample_n)) %>% 
  unnest(sample) %>% 
  mutate(ids = as.character(FK_FISH_ID)) %>% 
  pull(ids)

ids_PBGWRN <- list("KSPORT18" = ids_PBGWRN)

PoolCollections.GCL(collections = "KSPORT18", loci = GAPSLoci_reordered, IDs = ids_PBGWRN, newname = "PBGWRNSport_2018")
```

Verify that we picked fish appropriately.
```{r sport_PBGWRN_mixture_verify}
PBGWRNSport_2018.gcl$attributes %>% 
  count(site, biweek) %>% 
  spread(site, n, fill = 0)
```

Save genotypes for sport strata.
```{r save_sport_PBGWRN_strata_genotypes}
save_sillys(sillyvec = "PBGWRNSport_2018", path = "../Genotypes/strata/")
```

### OutsidePer1

What was the plan (i.e. ideal mixture sample size per biweek)?
```{r sport_OutsidePer1_mixture_ideal}
# What does proportional sampling look like?
extraction_OutsidePer1 <- join_sport %>% 
  filter(fishery == "Outside_early") %>% 
  arrange(biweek) %>% 
  mutate(p_harvest = round(harvest / sum(harvest) * 797)) %>%  # if we want 797 samples proportional to harvest by SW
  mutate(n_sufficeint = n >= p_harvest) %>% 
  mutate(n_remainings = n - p_harvest) %>% 
  mutate(n_extract = pmin(n, p_harvest)) %>% 
  select(site, biweek, n_extract)

extraction_OutsidePer1 %>% 
  spread(site, n_extract)
```

What do we have (i.e. how many fish per biweek made it through genotypeing)? Make adjustments
```{r sport_OutsidePer1_mixture_n}
(selection_OutsidePer1 <- KSPORT18.gcl$attributes %>% 
  filter(fishery == "Outside_early") %>% 
  count(site, biweek) %>% 
  right_join(extraction_OutsidePer1, by = c("site", "biweek")) %>% 
  replace_na(list(n = 0)) %>% 
  mutate(diff = n - n_extract) %>% 
  mutate(n_select = pmin(n, n_extract)))
```

Pick fish and create mixture.
```{r sport_OutsidePer1_mixture_create}
ids_OutsidePer1 <- KSPORT18.gcl$attributes %>% 
  filter(fishery == "Outside_early") %>% 
  nest(-site, -biweek) %>% 
  right_join(filter(selection_OutsidePer1, n_select > 0), by = c("site", "biweek")) %>% 
  mutate(sample = map2(data, n_select, sample_n)) %>% 
  unnest(sample) %>% 
  mutate(ids = as.character(FK_FISH_ID)) %>% 
  pull(ids)

ids_OutsidePer1 <- list("KSPORT18" = ids_OutsidePer1)

PoolCollections.GCL(collections = "KSPORT18", loci = GAPSLoci_reordered, IDs = ids_OutsidePer1, newname = "OutsidePer1Sport_2018")
```

Verify that we picked fish appropriately.
```{r sport_OutsidePer1_mixture_verify}
OutsidePer1Sport_2018.gcl$attributes %>% 
  count(site, biweek) %>% 
  spread(site, n, fill = 0)
```

Save genotypes for sport strata.
```{r save_sport_OutsidePer1_strata_genotypes}
save_sillys(sillyvec = "OutsidePer1Sport_2018", path = "../Genotypes/strata/")
```

### OutsidePer2

What was the plan (i.e. ideal mixture sample size per biweek)?
```{r sport_OutsidePer2_mixture_ideal}
# What does proportional sampling look like?
extraction_OutsidePer2 <- join_sport %>% 
  filter(fishery == "Outside_late") %>% 
  arrange(biweek) %>% 
  mutate(p_harvest = round(harvest / sum(harvest) * 555)) %>%  # if we want 555 samples proportional to harvest by SW
  mutate(n_sufficeint = n >= p_harvest) %>% 
  mutate(n_remainings = n - p_harvest) %>% 
  mutate(n_extract = pmin(n, p_harvest)) %>% 
  select(site, biweek, n_extract)

extraction_OutsidePer2 %>% 
  spread(site, n_extract)
```

What do we have (i.e. how many fish per biweek made it through genotypeing)? Make adjustments
```{r sport_OutsidePer2_mixture_n}
(selection_OutsidePer2 <- KSPORT18.gcl$attributes %>% 
  filter(fishery == "Outside_late") %>% 
  count(site, biweek) %>% 
  right_join(extraction_OutsidePer2, by = c("site", "biweek")) %>% 
  replace_na(list(n = 0)) %>% 
  mutate(diff = n - n_extract) %>% 
  mutate(n_select = pmin(n, n_extract)))
```

Pick fish and create mixture.
```{r sport_OutsidePer2_mixture_create}
ids_OutsidePer2 <- KSPORT18.gcl$attributes %>% 
  filter(fishery == "Outside_late") %>% 
  nest(-site, -biweek) %>% 
  right_join(filter(selection_OutsidePer2, n_select > 0), by = c("site", "biweek")) %>% 
  mutate(sample = map2(data, n_select, sample_n)) %>% 
  unnest(sample) %>% 
  mutate(ids = as.character(FK_FISH_ID)) %>% 
  pull(ids)

ids_OutsidePer2 <- list("KSPORT18" = ids_OutsidePer2)

PoolCollections.GCL(collections = "KSPORT18", loci = GAPSLoci_reordered, IDs = ids_OutsidePer2, newname = "OutsidePer2Sport_2018")
```

Verify that we picked fish appropriately.
```{r sport_OutsidePer2_mixture_verify}
OutsidePer2Sport_2018.gcl$attributes %>% 
  count(site, biweek) %>% 
  spread(site, n, fill = 0)
```

Save genotypes for sport strata.
```{r save_sport_OutsidePer2_strata_genotypes}
save_sillys(sillyvec = "OutsidePer2Sport_2018", path = "../Genotypes/strata/")
```

# Data QA

Standard data QA:

  * Remove fish missing <80% genotypes
  * Remove duplicates (>95% genotype concordance)

```{r sport_mixnames}
sport_2018_mixnames <- str_replace(string = dget("../../SEAK17/Objects/Sport_Mixtures.txt"), pattern = "2017", replacement = "2018")
save_objects(objects = "sport_2018_mixnames", path = "../Objects/")
```


```{r sport_QA}
# original sample sizes
sport_2018_sample_sizes <- tibble(silly = sport_2018_mixnames,
                                   genotyped = sapply(sport_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# missing
sport_2018_missing <- RemoveIndMissLoci.GCL(sillyvec = sport_2018_mixnames, proportion = 0.8)
save_objects("sport_2018_missing", "../Objects/")

sport_2018_sample_sizes <- sport_2018_sample_sizes %>% 
  mutate(missing = genotyped - sapply(sport_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# duplicate
sport_2018_duplicates <- CheckDupWithinSilly.GCL(sillyvec = sport_2018_mixnames, loci = GAPSLoci_reordered, quantile = NULL, minproportion = 0.95)
(sport_2018_duplicates_summary <- sapply(sport_2018_mixnames, function(x) {sport_2018_duplicates[[x]]$report}))
save_objects("sport_2018_duplicates_summary", "../Objects/")

sport_2018_duplciates_removed <- RemoveDups.GCL(dupcheck = sport_2018_duplicates)

sport_2018_sample_sizes <- sport_2018_sample_sizes %>% 
  mutate(duplicate = genotyped - missing - sapply(sport_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))

# final
sport_2018_sample_sizes <- sport_2018_sample_sizes %>% 
  mutate(final = sapply(sport_2018_mixnames, function(x) {get(paste0(x, ".gcl"))$n }))
sport_2018_sample_sizes
save_objects("sport_2018_sample_sizes", "../Objects/")

write_csv(sport_2018_sample_sizes, "../Tables/sport_2018_sample_sizes.csv")
```

Save post-QA genotypes
```{r sport_post_QA}
if(!dir.exists("../Genotypes/strata_postQA/")) {dir.create("../Genotypes/strata_postQA/")}
save_sillys(sillyvec = sport_2018_mixnames, path = "../Genotypes/strata_postQA")
```
# Create *BAYES* files

## Directory setup

First need to set up *BAYES* directory structure and copy over baseline file and *BAYES* objects. This was already done when we ran TBR.

## Create mixtures

Save the fortran format and create TBR *BAYES* mixture files. This was already done when we ran TBR.
```{r sport_BAYES_mixtures}
# mixfortran <- CreateMixture.GCL(sillys = TBR_sillys[1], loci = GAPSLoci_reordered, IDs = NULL, mixname = TBR_mixnames[TBR_sillys[1]], dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
# save_objects("mixfortran", "../Objects/")

sapply(sport_2018_mixnames, function(mix) {
  CreateMixture.GCL(sillys = mix, loci = GAPSLoci_reordered, IDs = NULL, mixname = mix, dir = "../BAYES/Mixture", type = "BAYES", PT = FALSE)
} )
```

## Create priors

New this year, I will be analyzing **ALL** Chinook mixtures with the full 33 reporting groups. Fortunately I had already re-summarized sport for 2017 at 33RG. 

```{r sport_read_2017_estimates}
SummerRet1_2013_33RG_EstimatesStats <- dget("../../SEAK17/Estimates objects/Sport_2017_33RG_EstimatesStats.txt")

sport_2017_means_33RG <- sapply(c(SummerRet1_2013_33RG_EstimatesStats), function(mix) {
  mix[, "mean"]
} )

dimnames(sport_2017_means_33RG)
```

Change column names for 2018 mixtures.
```{r sport_setup_2018_priors}
# Fix dimnames
colnames(sport_2017_means_33RG) <- str_replace(string = colnames(sport_2017_means_33RG), pattern = "2017", replacement = "2018")

# Verify
apply(sport_2017_means_33RG, 2, sum)
```

Now create 2018 priors.
```{r sport_create_2018_priors}
sport_2018_priors <- apply(sport_2017_means_33RG, 2, function(mix) {
  Prior.GCL(groupvec = GroupVec33RG_357, groupweights = mix, minval = 0.01)
} )
colnames(sport_2018_priors) <- sport_2018_mixnames
save_objects("sport_2018_priors", "../Objects/")
```

## Create control files

Now that we have priors, just need to create *BAYES* control files.
```{r sport_BAYES_control}
sapply(sport_2018_mixnames, function(mix) {
  CreateControlFile.GCL(sillyvec = SEAKPops357, loci = GAPSLoci_reordered, mixname = mix, basename = "GAPS357pops13loci", suffix = "", nreps = 40000,
                        nchains = 5, groupvec = GroupVec33RG_357, priorvec = sport_2018_priors[, mix], initmat = GAPS357PopsInits, 
                        dir = "../BAYES/Control", seeds = WASSIPSockeyeSeeds, thin = c(1, 1, 100), mixfortran = mixfortran, 
                        basefortran = bayesfortran_357, switches = "F T F T T T F")
} )
```

## Create output directories

```{r sport_BAYES_output}
sapply(sport_2018_mixnames, function(mix) {dir.create(paste0("../BAYES/Output/", mix))} )
```

# Summarize *BAYES* results

Summarize results for both the full 33 reporting groups, the 5 TBR groups, 3 TBR groups, and 2 TBR groups.

## 33 reporting groups

Create standard summary and save.
```{r sport_BAYES_summarise_33RG}
# full 33 reporting groups
SummerRet1_2018_33RG_EstimatesStats <- 
  CustomCombineBAYESOutput.GCL(groupvec = 1:33, groupnames = GroupNames33, maindir = "../BAYES/Output", mixvec = sport_2018_mixnames[1:4],
                               prior = "", ext = "RGN", nchains = 5, burn = 0.5, alpha = 0.1, PosteriorOutput = FALSE)

# dir.create("../Estimates objects")
save_objects(c("SummerRet1_2018_33RG_EstimatesStats"), "../Estimates objects")
```

Check Gelman-Rubin
```{r sport_GR_33RG}
any(sapply(SummerRet1_2018_33RG_EstimatesStats, function(mix) {mix[, "GR"]} ) > 1.2)
sum(sapply(SummerRet1_2018_33RG_EstimatesStats, function(mix) {mix[, "GR"]} ) > 1.2)
sapply(SummerRet1_2018_33RG_EstimatesStats, function(mix) {mix[, "GR"]} )
```

Just Alsek in NO quadrant, estimate is super low, so no big deal.
```{r}
SummerRet1_2018_33RG_EstimatesStats[["SummerRet1NO_2018"]]["Alsek", ]
```
